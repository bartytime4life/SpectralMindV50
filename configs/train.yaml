# ──────────────────────────────────────────────────────────────────────────────
# SpectraMind V50 — Training Config (Hydra 1.x / PyTorch Lightning 2.x)
# Top-level composed configuration for model training.
#
# Usage (examples):
#   python -m spectramind train
#   python -m spectramind train env=kaggle precision.mode=bf16-mixed trainer.max_epochs=30
#   python -m spectramind train loss=composite loss.composite.weights.nonneg=0.7
#   python -m spectramind train training/callbacks@training.callbacks=callbacks_fast
# ──────────────────────────────────────────────────────────────────────────────

# Composition: swap any group at CLI
defaults:
  - env: local                        # or: kaggle / ci / debug
  - data: nominal                     # dataset profile (nominal/kaggle/splits)
  - calib: nominal                    # calibration pipeline settings
  - model: v50                        # model architecture (dual encoders + decoder)
  - training: lightning               # base PL Trainer params
  - training/callbacks@training.callbacks: callbacks   # bundle of callbacks
  - loss: composite                   # physics-informed composite loss
  - logger: jsonl                     # logging backend (jsonl/csv/wandb)
  - override hydra/job_logging: disabled
  - override hydra/hydra_logging: disabled

# High-level experiment metadata
experiment:
  name: "spectramind_v50_train"
  tags: ["v50", "train", "fgs1", "airs"]
  notes: ""                           # free-form; override from CLI if needed

# Canonical paths (ENV-DRIVEN for portability: local/CI/Kaggle)
paths:
  data_root: ${env.data_root}
  artifacts_root: ${env.artifacts_root}
  runs: ${paths.artifacts_root}/runs
  logs: ${hydra:run.dir}/logs
  checkpoints: ${hydra:run.dir}/checkpoints
  reports: ${hydra:run.dir}/reports
  cache: ${paths.artifacts_root}/cache
  manifests: ${paths.artifacts_root}/manifests

# Reproducibility & backend knobs (torch <-> cudnn bridged)
seed: ${env.reproducibility.seed}
reproducibility:
  torch_deterministic_algorithms: ${env.reproducibility.deterministic}
  cudnn_benchmark: false
  cudnn_deterministic: ${env.reproducibility.deterministic}
  allow_tf32: false                    # raise only after validating numerics
  python_hash_seed: ${seed}

# Precision (Hydra-friendly structure)
precision:
  mode: "16-mixed"                    # "32-true" | "16-mixed" | "bf16-mixed"
  tf32:
    allow: ${reproducibility.allow_tf32}
    cudnn_allow: ${reproducibility.allow_tf32}
  grad_scaler:                        # used when mode == "16-mixed"
    enabled: true
    init_scale: 65536
    growth_interval: 2000

# Optional PyTorch 2.x compiler (TorchDynamo); default off
compile:
  enabled: false
  mode: "default"                     # "default" | "reduce-overhead" | "max-autotune"
  fullgraph: false
  dynamic: false

# Data pipeline (defaults; dataset group may override)
data:
  batch_size:
    train: 64
    val: 64
    test: 64
  num_workers: ${env.num_workers}
  pin_memory: true
  persistent_workers: true
  prefetch_factor: 2
  drop_last: true
  augment:
    enabled: true
    jitter: 0.01
    dropout: 0.0
  normalization:
    enabled: true
    method: "zscore"                   # "minmax" | "none"

# PyTorch Lightning Trainer (PL 2.x)
trainer:
  max_epochs: 50
  min_epochs: 1
  accelerator: ${env.device}           # "cuda" | "cpu"
  devices: 1
  strategy: auto                       # "auto" | "ddp" | "ddp_find_unused_parameters_false" etc.
  precision: ${precision.mode}
  accumulate_grad_batches: 2
  gradient_clip_val: 1.0
  gradient_clip_algorithm: "norm"
  log_every_n_steps: 50
  val_check_interval: 0.25
  check_val_every_n_epoch: null
  deterministic: ${env.reproducibility.deterministic}
  enable_checkpointing: true
  enable_model_summary: true
  detect_anomaly: false
  benchmark: false
  profiler: null
  callbacks: ${training.callbacks.callbacks}

# Optimizer / Scheduler (composable; warmup → cosine is the default policy)
optimizer:
  name: "AdamW"
  _target_: torch.optim.AdamW
  lr: 3e-4
  weight_decay: 1e-2
  betas: [0.9, 0.999]
  eps: 1e-8
  lr_scaling:
    enabled: false                     # set true if you want global-batch scaling
    reference_batch_size: 256          # effective global batch (accum * gpus * per-gpu bs)

scheduler:
  policy: "warmup_cosine"              # "cosine" | "warmup_cosine" | "none"
  warmup:
    enabled: true
    steps: 1000
    mode: "linear"
    start_factor: 1.0e-3               # lr starts at start_factor * base_lr
  cosine:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    T_max: ${trainer.max_epochs}
    eta_min: 1.0e-6

# Loggers (select via defaults: jsonl | csv | wandb)
logger:
  jsonl:
    log_dir: ${paths.logs}/jsonl
    append: true
    flush_every: 1
  csv:
    save_dir: ${paths.logs}/csv
    filename: "metrics.csv"
  wandb:
    project: "spectramind-v50"
    entity: null
    mode: disabled                     # set to "online" with WANDB_API_KEY
    tags: ${experiment.tags}
    notes: ${experiment.notes}
    save_code: true

# Composite physics-informed loss (weights feed src/spectramind/losses/composite.py)
loss:
  composite:
    weights:
      gll: 1.0
      smoothness: 0.2
      nonneg: 0.5
      band_coherence: 0.3
      calibration: 0.5
    params:
      smoothness:
        order: 2
        lambda_max: 0.2
      nonneg:
        margin: 0.0
        penalty: "l2"                   # or "hinge"
      band_coherence:
        window: 5
        lambda_max: 0.3
      calibration:
        align_bins: true
        lambda_max: 0.5

# Callback bundle (swappable via defaults)
training:
  callbacks:
    callbacks: []                      # e.g., ["model_checkpoint", "early_stopping", ...]

# Evaluation / reporting passes
evaluation:
  enable_test_after_fit: true
  save_report: true
  report_dir: ${paths.reports}
  figures:
    histograms: true
    scatter_mu_sigma: true
    per_bin_stats: true

# Runtime environment reflection (fed by env group)
env_reflection:
  device: ${env.device}
  num_workers: ${env.num_workers}
  seed: ${seed}

# Hydra runtime (each run lands under env.artifacts_root)
hydra:
  run:
    dir: ${paths.runs}/${now:%Y-%m-%d_%H-%M-%S}
  sweep:
    dir: ${paths.artifacts_root}/sweeps
    subdir: ${hydra.job.num}
  job:
    name: ${experiment.name}
