# configs/training/scheduler.yaml
# ======================================================================
# SpectraMind V50 â€” Learning-Rate Scheduler (Hydra sub-config)
# ======================================================================
# Select a scheduler via `name` and tune its section below. This file is
# read by the training stage to build the torch/PL scheduler and (optionally)
# a warmup schedule that precedes it.
# ======================================================================

# -------------------------
# Selection
# -------------------------
# one of: cosine_annealing | cosine_warm_restarts | one_cycle
#         | reduce_on_plateau | step | exponential | polynomial | constant
name: cosine_annealing

# -------------------------
# PyTorch Lightning integration
# -------------------------
pl:
  interval: epoch              # "step" | "epoch"
  frequency: 1                 # apply every N intervals
  monitor: val/loss            # metric to watch (for plateau/one_cycle with monitors)
  strict: true                 # raise if monitor is missing when required

# -------------------------
# Warmup (executed BEFORE the main scheduler)
# -------------------------
warmup:
  enabled: true
  strategy: linear             # "linear" | "cosine"
  steps: 500                   # prefer steps on Kaggle; stable with AMP
  min_lr: 1.0e-7               # starting LR
  max_lr: ${optimizer.lr}      # LR at end of warmup
  # If you prefer epoch-based warmups, set steps: null and use:
  epochs: null                 # e.g., 3

# -------------------------
# Cosine Annealing (no restarts)
# -------------------------
cosine_annealing:
  # If pl.interval == "epoch", T_max = ${trainer.max_epochs}
  # If pl.interval == "step", set T_max = total_update_steps (trainer-estimated)
  T_max: ${trainer.max_epochs}
  eta_min: 1.0e-6
  last_epoch: -1

# -------------------------
# Cosine Annealing with Warm Restarts
# -------------------------
cosine_warm_restarts:
  T_0: 10                      # first cycle length (epochs or steps)
  T_mult: 2                    # cycle length multiplier
  eta_min: 1.0e-6

# -------------------------
# One-Cycle policy (fast convergence)
# -------------------------
one_cycle:
  max_lr: ${optimizer.lr}      # peak LR (can be list for param groups)
  pct_start: 0.3               # warmup fraction of cycle
  div_factor: 25.0             # initial_lr = max_lr / div_factor
  final_div_factor: 10000.0    # min_lr = initial_lr / final_div_factor
  total_steps: null            # set if known; else PL infers from epochs * steps_per_epoch
  epochs: ${trainer.max_epochs}
  steps_per_epoch: null
  three_phase: false
  anneal_strategy: cos         # "cos" | "linear"

# -------------------------
# Reduce-on-Plateau (robust on noisy validation)
# -------------------------
reduce_on_plateau:
  mode: min
  factor: 0.5
  patience: 4
  threshold: 1.0e-4
  threshold_mode: rel
  cooldown: 0
  min_lr: 1.0e-6
  eps: 1.0e-8
  monitor: ${pl.monitor}       # keep in sync

# -------------------------
# Step Decay
# -------------------------
step:
  step_size: 10                # epochs/steps between decays
  gamma: 0.5                   # LR *= gamma

# -------------------------
# Exponential Decay
# -------------------------
exponential:
  gamma: 0.98                  # applied per interval

# -------------------------
# Polynomial Decay (poly schedule)
# -------------------------
polynomial:
  total_iters: ${trainer.max_epochs}   # or total update steps if step-based
  power: 1.0                           # 1.0 = linear decay
  end_lr: 1.0e-6                       # final LR at the end
  cycle: false

# -------------------------
# Constant LR (ablations/debug)
# -------------------------
constant:
  lr: ${optimizer.lr}

# -------------------------
# Safety / floor
# -------------------------
limits:
  lr_min: 1.0e-7               # clamp floor for any schedule (numeric safety)
  lr_max: ${optimizer.lr}      # clamp ceiling to avoid overshoot with warmup

# -------------------------
# Fine-tune helpers (optional staged decay)
# -------------------------
stages:
  enabled: false
  # Example: after N epochs, switch scheduler or tighten LR
  plan:
    - at_epoch: 0
      override:
        name: cosine_annealing
        cosine_annealing:
          T_max: ${trainer.max_epochs}
          eta_min: 1.0e-6
    - at_epoch: 20
      override:
        name: reduce_on_plateau
        reduce_on_plateau:
          factor: 0.5
          patience: 2
          min_lr: 1.0e-6
          monitor: ${pl.monitor}
