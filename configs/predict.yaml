# ──────────────────────────────────────────────────────────────────────────────
# SpectraMind V50 — Inference / Prediction Config (Hydra 1.x / PL 2.x)
# Batch prediction & submission formatting.
#
# Examples:
#   python -m spectramind predict checkpoint.path=artifacts/checkpoints/last.ckpt
#   python -m spectramind predict precision.mode=16-mixed submission.format=wide_csv
#   python -m spectramind predict tta.enabled=true tta.n=8 postprocess.smooth_mu.enabled=true
# ──────────────────────────────────────────────────────────────────────────────

defaults:
  - env: local              # or kaggle / ci / debug
  - data: kaggle            # dataset profile for test-set loading
  - calib: nominal          # if inference needs calibrated tensors
  - model: v50              # model architecture used at train time
  - logger: jsonl           # logging backend (jsonl/csv/wandb)
  - override hydra/job_logging: disabled
  - override hydra/hydra_logging: disabled

# High-level experiment metadata
experiment:
  name: "spectramind_v50_predict"
  tags: ["v50", "predict", "submission"]
  notes: ""

# Canonical paths (ENV-driven: portable across local/CI/Kaggle)
paths:
  data_root: ${env.data_root}
  artifacts_root: ${env.artifacts_root}
  runs: ${paths.artifacts_root}/runs
  logs: ${hydra:run.dir}/logs
  outputs: ${paths.artifacts_root}/predictions
  checkpoints: ${paths.artifacts_root}/checkpoints
  schema_dir: ${hydra:runtime.cwd}/schemas

# Runtime controls (deterministic by default)
runtime:
  seed: ${env.reproducibility.seed}
  deterministic: ${env.reproducibility.deterministic}
  allow_tf32: false                 # enable only after validating numerics on your GPU
  device: ${env.device}             # "cuda" | "cpu" (from env)
  inference_mode: true
  cudnn_benchmark: false

# Precision (Hydra-structured, like train)
precision:
  mode: "32-true"                   # "32-true" | "16-mixed" | "bf16-mixed"
  tf32:
    allow: ${runtime.allow_tf32}
    cudnn_allow: ${runtime.allow_tf32}
  grad_scaler:
    enabled: false                  # inference only; keep off

# DataLoader (uses env defaults)
dataloader:
  batch_size: 32
  num_workers: ${env.num_workers}
  pin_memory: true
  persistent_workers: true
  prefetch_factor: 2
  drop_last: false

# Checkpoint selection & loading
checkpoint:
  path: ${oc.env:SM_MODEL_CKPT, ${paths.checkpoints}/last.ckpt}
  strict: true
  fail_if_missing: true
  fallback_glob:
    enabled: true
    pattern: "${paths.checkpoints}/**/*.ckpt"
    recursive: true
  rank_zero_only: true              # avoid double logs in DDP

# Test-time augmentation (TTA)
tta:
  enabled: false
  n: 4
  flips: false
  jitter:
    enabled: false
    sigma: 0.005
  seed_offset: 1000
  aggregate:
    mu: "mean"                      # "mean" | "median"
    sigma: "var_mean_law"           # variance–mean law combiner

# Ensemble across multiple checkpoints
ensemble:
  enabled: false
  checkpoints: []                   # ["${paths.checkpoints}/fold1.ckpt", ...]
  aggregate:
    mu: "mean"
    sigma: "var_mean_law"

# Post-processing safety & priors
postprocess:
  clamp_nonneg_sigma: true
  epsilon_sigma: 1.0e-9
  enforce_nonneg_mu: false
  smooth_mu:
    enabled: false
    method: "laplacian"             # "laplacian" | "savitzky_golay"
    weight: 0.05
    window: 7
    polyorder: 2

# Submission formatting & validation
submission:
  validate_schema: true
  schema_path: ${paths.schema_dir}/submission.schema.json
  format: "jsonl"                   # "jsonl" | "wide_csv"

  jsonl:
    filename: "submission.jsonl"
    indent: 0
    keys:
      id: "id"
      mu: "mu"
      sigma: "sigma"

  wide_csv:
    filename: "submission.csv"
    mu_prefix: "mu_"
    sigma_prefix: "sigma_"
    digits: 6
    include_header: true
    enforce_column_order: true
    # keep a predictable column order for deterministic zips
    order_strategy: "lexicographic"  # "lexicographic" | "schema" (repo-specific)

# Optional offline metrics (when holdout labels exist)
metrics:
  compute_offline: false
  gll:
    enabled: true
    # add FGS1 upweight if you score offline like the leaderboard
    fgs1_weight: ${oc.env:SM_GLL_W_FGS1, 58.0}
  summary:
    save_json: true
    path: ${paths.outputs}/metrics.json

# Diagnostics artifacts (plots & quick summaries)
diagnostics:
  enabled: true
  out_dir: ${hydra:run.dir}/diagnostics
  plots:
    per_bin_mu_hist: true
    per_bin_sigma_hist: true
    mu_vs_sigma_scatter: true
  save_csv_summary: true

# Logging backends
logger:
  jsonl:
    log_dir: ${paths.logs}/jsonl
    append: true
  csv:
    save_dir: ${paths.logs}/csv
    filename: "predict_metrics.csv"
  wandb:
    project: "spectramind-v50"
    entity: null
    mode: disabled
    tags: ${experiment.tags}
    notes: ${experiment.notes}
    rank_zero_only: true

# Hydra runtime (under env.artifacts_root)
hydra:
  run:
    dir: ${paths.runs}/${now:%Y-%m-%d_%H-%M-%S}_predict
  sweep:
    dir: ${paths.artifacts_root}/sweeps
    subdir: ${hydra.job.num}
  job:
    name: ${experiment.name}
