{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SpectraMind V50 \u2014 Kaggle Training Notebook (FGS1 + AIRS)\n\n",
        "**Goal:** Train SpectraMind V50 model *inside Kaggle* (no internet), using attached competition dataset and a code/weights dataset.\n\n",
        "**Outputs:**\n",
        "- `outputs/df_shapes.csv` (dataset shapes)\n",
        "- `outputs/summary.json` (env, file counts, issues)\n",
        "- `outputs/train_metrics.json` (metrics)\n",
        "- `outputs/train_manifest.json` (checkpoint, metrics, timestamp)\n\n",
        "**Behavior:** If `spectramind.cli_hooks.notebook_train` is available, we call it with a Kaggle-safe config; else, a 1-second demo path writes a dummy checkpoint + metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, sys, platform, json, time, warnings\n",
        "from pathlib import Path\n",
        "from typing import Dict, Optional\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "BIN_COUNT = 283\n",
        "COMP_DIR = Path('/kaggle/input/ariel-data-challenge-2025')\n",
        "REPO_ROOT_CANDIDATES = [Path.cwd(), Path.cwd().parent, Path.cwd().parent.parent]\n",
        "\n",
        "def detect_env() -> Dict[str, str]:\n",
        "    env = {\n",
        "        'is_kaggle': COMP_DIR.exists(),\n",
        "        'platform': platform.platform(),\n",
        "        'python': sys.version.replace('\\n', ' '),\n",
        "        'cwd': str(Path.cwd()),\n",
        "        'repo_root': None,\n",
        "    }\n",
        "    for c in REPO_ROOT_CANDIDATES:\n",
        "        if (c/'configs').exists() and (c/'schemas').exists():\n",
        "            env['repo_root'] = str(c.resolve()); break\n",
        "    return env\n",
        "\n",
        "ENV = detect_env(); ENV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def resolve_paths(env: Dict) -> Dict[str, Optional[Path]]:\n",
        "    repo_root = Path(env['repo_root']) if env['repo_root'] else None\n",
        "    outputs = Path('outputs'); outputs.mkdir(parents=True, exist_ok=True)\n",
        "    artifacts = Path('artifacts'); artifacts.mkdir(parents=True, exist_ok=True)\n",
        "    return {\n",
        "        'competition': COMP_DIR if env['is_kaggle'] else None,\n",
        "        'repo_root': repo_root,\n",
        "        'schemas': (repo_root/'schemas') if repo_root else None,\n",
        "        'configs': (repo_root/'configs') if repo_root else None,\n",
        "        'artifacts': artifacts,\n",
        "        'outputs': outputs,\n",
        "    }\n",
        "PATHS = resolve_paths(ENV); PATHS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def list_files(base: Optional[Path], patterns=('*.csv','*.parquet','*.json','*.npz','*.pt','*.pth'), limit=80):\n",
        "    if not base or not base.exists(): return []\n",
        "    out = []\n",
        "    for pat in patterns:\n",
        "        out.extend([str(p) for p in base.rglob(pat)])\n",
        "    return sorted(out)[:limit]\n",
        "\n",
        "inventory = {\n",
        "    'kaggle_input': list_files(PATHS['competition']),\n",
        "    'artifacts': list_files(PATHS['artifacts']),\n",
        "}\n",
        "print(json.dumps(inventory, indent=2)[:2000])\n",
        "\n",
        "issues = []\n",
        "if ENV['is_kaggle'] and not (PATHS['competition'] and (PATHS['competition']/ 'train.csv').exists()):\n",
        "    issues.append('Missing train.csv in competition dataset. Attach Ariel Data Challenge 2025 dataset.')\n",
        "print('Issues:' if issues else 'No blocking issues detected.')\n",
        "for m in issues: print(' -', m)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def profile_df_shapes():\n",
        "    rows = []\n",
        "    for key, files in inventory.items():\n",
        "        for f in files:\n",
        "            p = Path(f)\n",
        "            if p.suffix=='.csv':\n",
        "                try:\n",
        "                    df = pd.read_csv(p, nrows=5)\n",
        "                    rows.append({'source': key, 'file': str(p), 'cols': df.shape[1], 'rows_head': df.shape[0]})\n",
        "                except Exception: pass\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "shapes = profile_df_shapes()\n",
        "shapes.to_csv(PATHS['outputs']/ 'df_shapes.csv', index=False)\n",
        "print('Wrote outputs/df_shapes.csv'); shapes.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def run_train_via_hook():\n",
        "    try:\n",
        "        from spectramind.cli_hooks import notebook_train\n",
        "    except Exception as e:\n",
        "        print('spectramind hooks NOT available:', e); return None\n",
        "    config = {\n",
        "        'env': 'kaggle' if ENV['is_kaggle'] else 'local',\n",
        "        'data': {\n",
        "            'competition_dir': str(PATHS['competition']) if PATHS['competition'] else None,\n",
        "            'train_csv': str(PATHS['competition']/ 'train.csv') if PATHS['competition'] and (PATHS['competition']/ 'train.csv').exists() else None,\n",
        "        },\n",
        "        'training': {\n",
        "            'seed': 42,\n",
        "            'epochs': 5,\n",
        "            'batch_size': 32,\n",
        "            'precision': 'fp32',\n",
        "        },\n",
        "        'model': {\n",
        "            'name': 'v50',\n",
        "            'dual_encoders': True,\n",
        "        },\n",
        "        'loss': {\n",
        "            'gll_fgs1_weight': 58.0,\n",
        "        },\n",
        "        'outputs': {\n",
        "            'dir': str(PATHS['outputs']),\n",
        "            'save_dir': str(PATHS['artifacts'])\n",
        "        }\n",
        "    }\n",
        "    print('Config snapshot (train):'); print(json.dumps(config, indent=2))\n",
        "    t0 = time.time()\n",
        "    try:\n",
        "        ckpt_path, metrics = notebook_train(config=config)\n",
        "    except Exception as e:\n",
        "        print('Hooked training failed:', e); return None\n",
        "    dt = time.time() - t0\n",
        "    print(f'Hooked training completed in {dt:.1f}s')\n",
        "    return ckpt_path, metrics\n",
        "\n",
        "res = run_train_via_hook()\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def demo_train_fallback():\n",
        "    Path(PATHS['artifacts']).mkdir(parents=True, exist_ok=True)\n",
        "    ckpt = PATHS['artifacts']/ 'model_v50_demo.ckpt'\n",
        "    with open(ckpt, 'wb') as f: f.write(os.urandom(256))\n",
        "    metrics = {'train_loss': 0.123, 'val_loss': 0.234, 'elapsed_s': 1.0}\n",
        "    with open(PATHS['outputs']/ 'train_metrics.json', 'w') as f: json.dump(metrics, f, indent=2)\n",
        "    print('Demo: saved', ckpt)\n",
        "    return str(ckpt), metrics\n",
        "\n",
        "if res is None:\n",
        "    res = demo_train_fallback()\n",
        "\n",
        "ckpt_path, metrics = res\n",
        "manifest = {\n",
        "    'checkpoint': ckpt_path,\n",
        "    'metrics': metrics,\n",
        "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "}\n",
        "with open(PATHS['outputs']/ 'train_manifest.json', 'w') as f:\n",
        "    json.dump(manifest, f, indent=2)\n",
        "print('Wrote outputs/train_manifest.json'); manifest"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}