{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hdr-intro",
   "metadata": {},
   "source": [
    "# 00 â€” Exploration Notebook (SpectraMind V50)\n",
    "\n",
    "**Purpose**: Fast, repeatable EDA for the NeurIPS 2025 Ariel Data Challenge with Kaggle-aware paths, zero-internet defaults, and physics-informed guardrails.\n",
    "\n",
    "Runs in:\n",
    "1) **Kaggle** (competition dataset auto-mounted under `/kaggle/input/ariel-data-challenge-2025/`)\n",
    "2) **Local dev** (expects repo structure: `configs/`, `schemas/`, `data/`)\n",
    "3) **Bare env** (graceful skips if files absent)\n",
    "\n",
    "> Tips\n",
    "> - Keep heavy plots light; this should render under 2â€“3 minutes on Kaggle CPU.\n",
    "> - Use **matplotlib** only; avoid seaborn & style overrides for portability.\n",
    "> - Never hardcode secrets/paths; rely on the helpers below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hdr-setup",
   "metadata": {},
   "source": [
    "## ðŸ§­ Session Setup & Environment Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-env",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, platform, json, math, glob, warnings\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n", 
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "BIN_COUNT = 283\n",
    "COMP_DIR = Path('/kaggle/input/ariel-data-challenge-2025')\n",
    "REPO_ROOT_CANDIDATES = [Path.cwd(), Path.cwd().parent, Path.cwd().parent.parent]\n",
    "\n",
    "def detect_env() -> Dict[str, str]:\n",
    "    env = {\n",
    "        \"is_kaggle\": COMP_DIR.exists(),\n",
    "        \"platform\": platform.platform(),\n",
    "        \"python\": sys.version.replace(\"\\n\", \" \"),\n",
    "        \"cwd\": str(Path.cwd()),\n",
    "    }\n",
    "    for c in REPO_ROOT_CANDIDATES:\n",
    "        if (c/'configs').exists() and (c/'schemas').exists():\n",
    "            env[\"repo_root\"] = str(c.resolve())\n",
    "            break\n",
    "    else:\n",
    "        env[\"repo_root\"] = None\n",
    "    return env\n",
    "\n",
    "ENV = detect_env()\n",
    "ENV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hdr-paths",
   "metadata": {},
   "source": [
    "### âœ… Paths & Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_paths(env: Dict) -> Dict[str, Optional[Path]]:\n",
    "    repo_root = Path(env['repo_root']) if env['repo_root'] else None\n",
    "    outputs = Path('outputs'); outputs.mkdir(exist_ok=True, parents=True)\n",
    "    return {\n",
    "        \"competition\": COMP_DIR if env['is_kaggle'] else None,\n",
    "        \"repo_root\": repo_root,\n",
    "        \"data_raw\": (repo_root/'data'/'raw') if repo_root else None,\n",
    "        \"data_processed\": (repo_root/'data'/'processed') if repo_root else None,\n",
    "        \"schemas\": (repo_root/'schemas') if repo_root else None,\n",
    "        \"configs\": (repo_root/'configs') if repo_root else None,\n",
    "        \"artifacts\": (repo_root/'artifacts') if repo_root and (repo_root/'artifacts').exists() else None,\n",
    "        \"outputs\": outputs,\n",
    "    }\n",
    "PATHS = resolve_paths(ENV)\n",
    "PATHS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hdr-inventory",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Fast Inventory (CSV/Parquet/JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(base: Optional[Path], patterns=('*.csv','*.parquet','*.json'), limit=50):\n",
    "    if not base or not base.exists():\n",
    "        return []\n",
    "    out = []\n",
    "    for pat in patterns:\n",
    "        out.extend([str(p) for p in base.rglob(pat)])\n",
    "    return sorted(out)[:limit]\n",
    "\n",
    "inventory = {\n",
    "    \"kaggle_input\": list_files(PATHS[\"competition\"]),\n",
    "    \"data_raw\": list_files(PATHS[\"data_raw\"]),\n",
    "    \"data_processed\": list_files(PATHS[\"data_processed\"]),\n",
    "}\n",
    "inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hdr-schemas",
   "metadata": {},
   "source": [
    "## ðŸ§¾ (Optional) Schemas Preview\n",
    "If `schemas/` is present locally, preview top-level keys (no validation to keep runtime short)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-schemas",
   "metadata": {},
   "outputs": [],
   "source": [
    "schemas_preview = {}\n",
    "if PATHS[\"schemas\"] and PATHS[\"schemas\"].exists():\n",
    "    for name in (\"submission.schema.json\", \"events.schema.json\", \"config_snapshot.schema.json\"):\n",
    "        p = PATHS[\"schemas\"]/name\n",
    "        if p.exists():\n",
    "            try:\n",
    "                with open(p, 'r', encoding='utf-8') as f:\n",
    "                    j = json.load(f)\n",
    "                schemas_preview[name] = {\n",
    "                    \"title\": j.get(\"title\"),\n",
    "                    \"$schema\": j.get(\"$schema\"),\n",
    "                    \"required\": j.get(\"required\"),\n",
    "                    \"additionalProperties\": j.get(\"additionalProperties\"),\n",
    "                }\n",
    "            except Exception as e:\n",
    "                schemas_preview[name] = {\"error\": str(e)}\n",
    "schemas_preview if schemas_preview else \"No local schemas found.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hdr-tabular",
   "metadata": {},
   "source": [
    "## ðŸ”Ž Tabular Summaries (Guarded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-read",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_read_csv(p: Path, **kw):\n",
    "    try:\n",
    "        return pd.read_csv(p, **kw)\n",
    "    except Exception as e:\n",
    "        print(f'Failed to read {p}: {e}')\n",
    "        return None\n",
    "\n",
    "def safe_read_parquet(p: Path):\n",
    "    # Try pyarrow, then pandas fallback\n",
    "    try:\n",
    "        import pyarrow.parquet as pq\n",
    "        return pq.read_table(p).to_pandas()\n",
    "    except Exception:\n",
    "        try:\n",
    "            return pd.read_parquet(p)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to read parquet {p}: {e}')\n",
    "            return None\n",
    "\n",
    "dfs: Dict[str, Optional[pd.DataFrame]] = {}\n",
    "if PATHS[\"competition\"]:\n",
    "    for candidate in (\"train.csv\", \"test.csv\", \"train_star_info.csv\", \"test_star_info.csv\",\n",
    "                      \"adc_info.csv\", \"axis_info.parquet\", \"wavelengths.csv\", \"sample_submission.csv\"):\n",
    "        p = PATHS[\"competition\"]/candidate\n",
    "        if p.exists():\n",
    "            if p.suffix == '.csv':\n",
    "                dfs[candidate] = safe_read_csv(p)\n",
    "            elif p.suffix == '.parquet':\n",
    "                dfs[candidate] = safe_read_parquet(p)\n",
    "\n",
    "preview = {k: (v.head(5) if isinstance(v, pd.DataFrame) else None) for k,v in dfs.items()}\n",
    "list(preview.keys()), {k: v.shape for k,v in dfs.items() if hasattr(v, 'shape')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hdr-profile",
   "metadata": {},
   "source": [
    "### Basic Profiling Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_df(df: pd.DataFrame, name: str, max_cols: int = 20):\n",
    "    print(f'\\n=== {name} ===')\n",
    "    print(f'shape: {df.shape}')\n",
    "    display(df.head(3))\n",
    "    # Limit to numeric for speed; include object summary via nunique\n",
    "    num_desc = df.select_dtypes(include=[np.number]).describe().T\n",
    "    obj_nuniq = df.select_dtypes(include=['object']).nunique().sort_values(ascending=False)\n",
    "    display(num_desc.head(max_cols))\n",
    "    if not obj_nuniq.empty:\n",
    "        display(obj_nuniq.head(max_cols).to_frame('nunique'))\n",
    "    nulls = df.isnull().mean().sort_values(ascending=False)\n",
    "    display(nulls.head(max_cols).to_frame('null_frac'))\n",
    "\n",
    "for k, df in dfs.items():\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        profile_df(df, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hdr-plots",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Quick Plots (Matplotlib)\n",
    "Default colors only; plots render only if columns exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_hist(df: pd.DataFrame, col: str, bins: int = 50, title: str = None):\n",
    "    if col in df.columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        df[col].dropna().plot(kind='hist', bins=bins)\n",
    "        plt.title(title or f'Histogram â€” {col}')\n",
    "        plt.xlabel(col); plt.ylabel('count')\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "def maybe_line(df: pd.DataFrame, x: str, y: str, n: int = 1000, title: str = None):\n",
    "    if x in df.columns and y in df.columns:\n",
    "        sample = df[[x,y]].dropna().head(n)\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(sample[x].values, sample[y].values)\n",
    "        plt.title(title or f'{y} vs {x}')\n",
    "        plt.xlabel(x); plt.ylabel(y)\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "if \"train.csv\" in dfs and isinstance(dfs[\"train.csv\"], pd.DataFrame):\n",
    "    df = dfs[\"train.csv\"]\n",
    "    for candidate in [\"id\", \"target\", \"mu_000\", \"sigma_000\"]:\n",
    "        if candidate in df.columns:\n",
    "            maybe_hist(df, candidate, bins=40, title=f'{candidate} distribution')\n",
    "\n",
    "if \"axis_info.parquet\" in dfs and isinstance(dfs[\"axis_info.parquet\"], pd.DataFrame):\n",
    "    df = dfs[\"axis_info.parquet\"]\n",
    "    cols = df.columns.tolist()\n",
    "    if len(cols) >= 2:\n",
    "        maybe_line(df, cols[0], cols[1], title=f'{cols[1]} vs {cols[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hdr-physics",
   "metadata": {},
   "source": [
    "## ðŸ§ª Physics-Informed Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = []\n",
    "\n",
    "# Expect BIN_COUNT mu_* and sigma_* columns in train if present\n",
    "if \"train.csv\" in dfs and isinstance(dfs[\"train.csv\"], pd.DataFrame):\n",
    "    df = dfs[\"train.csv\"]\n",
    "    mu_cols = [c for c in df.columns if c.startswith('mu_')]\n",
    "    sigma_cols = [c for c in df.columns if c.startswith('sigma_')]\n",
    "    if mu_cols and len(mu_cols) != BIN_COUNT:\n",
    "        issues.append(f'Expected {BIN_COUNT} mu_* columns, found {len(mu_cols)}')\n",
    "    if sigma_cols and len(sigma_cols) != BIN_COUNT:\n",
    "        issues.append(f'Expected {BIN_COUNT} sigma_* columns, found {len(sigma_cols)}')\n",
    "    # Non-negativity for uncertainties\n",
    "    if sigma_cols:\n",
    "        neg_frac = (df[sigma_cols] < 0).to_numpy().mean()\n",
    "        if np.isfinite(neg_frac) and neg_frac > 0:\n",
    "            issues.append(f'Negative sigma fraction observed: {neg_frac:.4f}')\n",
    "\n",
    "issues or \"All basic sanity checks passed (or skipped due to missing inputs).\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hdr-export",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Export Light Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    \"env\": ENV,\n",
    "    \"file_counts\": {k: len(v) if isinstance(v, list) else 0 for k,v in inventory.items()},\n",
    "    \"dataframes\": {k: {\"rows\": int(v.shape[0]), \"cols\": int(v.shape[1])} for k,v in dfs.items() if hasattr(v,'shape')},\n",
    "    \"issues\": issues,\n",
    "}\n",
    "pd.DataFrame(summary[\"dataframes\"]).T.to_csv('outputs/df_shapes.csv', index=True)\n",
    "with open('outputs/summary.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print('Wrote outputs/df_shapes.csv and outputs/summary.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hdr-next",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Explore FGS1 lightcurves and AIRS spectral axes (`axis_info.parquet`) if present.\n",
    "- Wire Hydra configs to reproduce exact preprocessing.\n",
    "- Save plots under `outputs/` to keep the notebook clean/CI-friendly.\n",
    "- Keep runtime short; prefer sampling large tables.\n",
    "\n",
    "**Done.** ðŸŽ¯"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
