{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ›°ï¸ SpectraMind V50 â€” Kaggle Quickstart (Upgraded)\n\n",
        "## Whatâ€™s new vs prior version\n",
        "- Safer runtime & mount checks; pretty status banners\n",
        "- Centralized Hydra overrides (edit in one place)\n",
        "- Optional pretrained checkpoint attachment (for inference-only runs)\n",
        "- Auto-discover latest checkpoint if none specified\n",
        "- Stage timers + minimal JSON run summary\n",
        "- Better submission handling (copy/validate) + quick preview\n",
        "- Deterministic seeds for NumPy/PyTorch (if installed)\n",
        "- Graceful CLI error capture with readable stderr\n\n",
        "Two-kernel pattern supported:\n\n",
        "**Train** kernel â†’ publish weights as a private Kaggle Dataset â†’ **inference-only** kernel for daily submissions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Banner & helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, sys, json, time, shutil, subprocess, textwrap, traceback\n",
        "from pathlib import Path\n\n",
        "def banner(title: str):\n",
        "    pad = \"â•\" * max(0, 60 - len(title) - 2)\n",
        "    print(f\"\\n\\033[1;36mâ•”â• {title} {pad}\\033[0m\")\n\n",
        "def sec(s: float) -> str:\n",
        "    return f\"{s:.2f}s\"\n\n",
        "def run_cmd(cmd: list):\n",
        "    try:\n",
        "        print(\"â†’\", \" \".join(map(str, cmd)))\n",
        "        t0 = time.time()\n",
        "        out = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        dt = time.time() - t0\n",
        "        print(f\"âœ“ finished in {sec(dt)}\")\n",
        "        if out.stdout:\n",
        "            print(out.stdout)\n",
        "        if out.returncode != 0:\n",
        "            print(\"\\n\\033[1;31mâœ— command failed\\033[0m\")\n",
        "            if out.stderr:\n",
        "                print(out.stderr)\n",
        "            out.check_returncode()\n",
        "        return dt\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"\\n\\033[1;31mâœ— command raised CalledProcessError\\033[0m\")\n",
        "        print(e.stderr or \"\")\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Environment & paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "banner(\"Env & Paths\")\n\n",
        "IS_KAGGLE = Path(\"/kaggle\").exists()\n",
        "WORK = Path(\"/kaggle/working\") if IS_KAGGLE else Path.cwd()\n",
        "OUT = WORK / \"outputs\"; OUT.mkdir(parents=True, exist_ok=True)\n\n",
        "# ðŸ”§ EDIT THESE IF NEEDED (or just attach datasets using these mount points)\n",
        "REPO_ROOT = Path(\"/kaggle/input/spectramind-v50\")\n",
        "DATA_ROOT = Path(\"/kaggle/input/ariel-data-challenge-2025\")\n\n",
        "# Optional: A dataset containing a pre-trained checkpoint for inference-only runs\n",
        "CKPT_DATASET = Path(\"/kaggle/input/spectramind-v50-checkpoints\")  # change or set to None\n",
        "if not CKPT_DATASET.exists():\n",
        "    CKPT_DATASET = None\n\n",
        "print(\"IS_KAGGLE:\", IS_KAGGLE)\n",
        "print(\"REPO_ROOT:\", REPO_ROOT, \"exists:\", REPO_ROOT.exists())\n",
        "print(\"DATA_ROOT:\", DATA_ROOT, \"exists:\", DATA_ROOT.exists())\n",
        "print(\"CKPT_DATASET:\", CKPT_DATASET, \"exists:\" if CKPT_DATASET else None)\n",
        "print(\"WORK:\", WORK)\n\n",
        "assert REPO_ROOT.exists(), \"Attach your repo dataset as /kaggle/input/spectramind-v50\"\n",
        "assert DATA_ROOT.exists(), \"Attach the Ariel competition dataset as /kaggle/input/ariel-data-challenge-2025\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Install pinned deps (offline) & import package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "banner(\"Install & Import\")\n\n",
        "req = REPO_ROOT / \"requirements-kaggle.txt\"\n",
        "assert req.exists(), \"Missing requirements-kaggle.txt in the repo dataset\"\n\n",
        "# Fully offline install: uses any wheel dirs youâ€™ve attached as Kaggle datasets\n",
        "get_ipython().run_line_magic('pip', f'install -r \"{req}\" --no-index --find-links /kaggle/input --quiet')\n\n",
        "# Add repo src\n",
        "SRC = REPO_ROOT / \"src\"\n",
        "assert (SRC / \"spectramind\").exists(), \"Missing src/spectramind in the repo dataset\"\n",
        "sys.path.append(str(SRC))\n\n",
        "# Pretty printing\n",
        "try:\n",
        "    from rich import print as rprint\n",
        "except Exception:\n",
        "    rprint = print\n\n",
        "# Seeds (if present)\n",
        "try:\n",
        "    import numpy as np\n",
        "    np.random.seed(42)\n",
        "except Exception:\n",
        "    pass\n\n",
        "try:\n",
        "    import torch\n",
        "    torch.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "except Exception:\n",
        "    pass\n\n",
        "# Show GPU if available\n",
        "try:\n",
        "    import torch\n",
        "    rprint(f\":computer: Torch CUDA available: {torch.cuda.is_available()} | device_count={torch.cuda.device_count()}\")\n",
        "except Exception:\n",
        "    pass\n\n",
        "rprint(\":rocket: Environment ready.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Run config & switches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "banner(\"Run Config\")\n\n",
        "# Toggle stages\n",
        "DO_CALIBRATE   = True     # Raw â†’ calibrated cubes\n",
        "DO_PREPROCESS  = False    # Calibrated â†’ tensors (enable if your repo has this stage)\n",
        "DO_TRAIN       = True     # Train Î¼,Ïƒ model (disable for inference-only)\n",
        "DO_PREDICT     = True     # Predict on test â†’ submission.csv\n",
        "DO_DIAGNOSE    = True     # GLL/FFT/UMAP/symbolic checks (fast mode option)\n",
        "DO_PACKAGE     = True     # submission.zip\n\n",
        "# Runtime\n",
        "FAST_MODE      = True     # Safe defaults for Kaggle 9h limit\n",
        "SEED           = 42\n",
        "USE_CLI        = True     # Prefer CLI; set False to use Python API wrappers\n\n",
        "# Optional pretrained weights for inference-only (if CKPT_DATASET attached)\n",
        "# If you know the exact file, put it here; else we'll auto-discover later.\n",
        "PRETRAINED_CKPT = None\n\n",
        "# Central Hydra overrides â€” edit here and they propagate to all stages\n",
        "HYDRA_OVERRIDES = [\n",
        "    \"+env=kaggle\",\n",
        "    f\"data.root={DATA_ROOT}\",\n",
        "    f\"seed={SEED}\",\n",
        "    f\"calib.fast={'true' if FAST_MODE else 'false'}\",\n",
        "    f\"preprocess.fast={'true' if FAST_MODE else 'false'}\",\n",
        "    f\"training.fast={'true' if FAST_MODE else 'false'}\",\n",
        "    f\"diagnostics.fast={'true' if FAST_MODE else 'false'}\",\n",
        "]\n",
        "print(\"HYDRA_OVERRIDES:\", HYDRA_OVERRIDES)\n\n",
        "# Snapshot config for reproducibility\n",
        "cfg = dict(\n",
        "    env=\"kaggle\", data_root=str(DATA_ROOT), fast=FAST_MODE, seed=SEED,\n",
        "    stages=dict(calibrate=DO_CALIBRATE, preprocess=DO_PREPROCESS, train=DO_TRAIN,\n",
        "                predict=DO_PREDICT, diagnose=DO_DIAGNOSE, package=DO_PACKAGE),\n",
        "    use_cli=USE_CLI,\n",
        ")\n",
        "with open(OUT/\"config_snapshot.json\", \"w\") as f:\n",
        "    json.dump(cfg, f, indent=2)\n",
        "print(\"Saved\", OUT/\"config_snapshot.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Stage: Calibrate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "times = {}\n",
        "if DO_CALIBRATE:\n",
        "    banner(\"Stage: Calibrate\")\n",
        "    if USE_CLI:\n",
        "        cmd = [sys.executable, \"-m\", \"spectramind\", \"calibrate\"] + HYDRA_OVERRIDES\n",
        "        times[\"calibrate\"] = run_cmd(cmd)\n",
        "    else:\n",
        "        from spectramind.pipeline import calibrate\n",
        "        t0 = time.time()\n",
        "        calibrate.run(config_name=\"calibrate\", overrides=HYDRA_OVERRIDES)\n",
        "        times[\"calibrate\"] = time.time() - t0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Stage: Preprocess (optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if DO_PREPROCESS:\n",
        "    banner(\"Stage: Preprocess\")\n",
        "    if USE_CLI:\n",
        "        cmd = [sys.executable, \"-m\", \"spectramind\", \"preprocess\"] + HYDRA_OVERRIDES\n",
        "        times[\"preprocess\"] = run_cmd(cmd)\n",
        "    else:\n",
        "        from spectramind.pipeline import preprocess\n",
        "        t0 = time.time()\n",
        "        preprocess.run(config_name=\"preprocess\", overrides=HYDRA_OVERRIDES)\n",
        "        times[\"preprocess\"] = time.time() - t0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Stage: Train (or skip for inference-only)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Optionally pull a checkpoint from attached dataset (inference-only)\n",
        "def auto_discover_checkpoint():\n",
        "    # 1) explicit\n",
        "    if PRETRAINED_CKPT and Path(PRETRAINED_CKPT).exists():\n",
        "        return PRETRAINED_CKPT\n",
        "    # 2) from CKPT_DATASET\n",
        "    if CKPT_DATASET:\n",
        "        cands = sorted(CKPT_DATASET.rglob(\"*.ckpt\")) + sorted(CKPT_DATASET.rglob(\"*.pth\"))\n",
        "        if cands:\n",
        "            return str(cands[-1])\n",
        "    # 3) from working dirs (if previously trained)\n",
        "    cands = sorted(Path(\".\").rglob(\"*.ckpt\")) + sorted(Path(\".\").rglob(\"*.pth\"))\n",
        "    if cands:\n",
        "        return str(cands[-1])\n",
        "    return None\n\n",
        "if DO_TRAIN:\n",
        "    banner(\"Stage: Train\")\n",
        "    if USE_CLI:\n",
        "        cmd = [sys.executable, \"-m\", \"spectramind\", \"train\"] + HYDRA_OVERRIDES\n",
        "        times[\"train\"] = run_cmd(cmd)\n",
        "    else:\n",
        "        from spectramind.pipeline import train\n",
        "        t0 = time.time()\n",
        "        train.run(config_name=\"train\", overrides=HYDRA_OVERRIDES)\n",
        "        times[\"train\"] = time.time() - t0\n",
        "else:\n",
        "    # Inference-only: ensure a checkpoint is available\n",
        "    ckpt = auto_discover_checkpoint()\n",
        "    print(\"Inference-only mode; discovered checkpoint:\", ckpt)\n",
        "    assert ckpt and Path(ckpt).exists(), \"No checkpoint found: attach a checkpoint dataset or set PRETRAINED_CKPT\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Stage: Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if DO_PREDICT:\n",
        "    banner(\"Stage: Predict\")\n",
        "    # If not training this run, pass in checkpoint via override if your predict stage accepts it (example key)\n",
        "    overrides = HYDRA_OVERRIDES.copy()\n",
        "    if not DO_TRAIN:\n",
        "        ckpt = auto_discover_checkpoint()\n",
        "        print(\"Using checkpoint:\", ckpt)\n",
        "        assert ckpt and Path(ckpt).exists(), \"Missing checkpoint for prediction\"\n",
        "        overrides.append(f\"predict.ckpt={ckpt}\")\n\n",
        "    if USE_CLI:\n",
        "        cmd = [sys.executable, \"-m\", \"spectramind\", \"predict\"] + overrides\n",
        "        times[\"predict\"] = run_cmd(cmd)\n",
        "    else:\n",
        "        from spectramind.pipeline import predict\n",
        "        t0 = time.time()\n",
        "        predict.run(config_name=\"predict\", overrides=overrides)\n",
        "        times[\"predict\"] = time.time() - t0\n\n",
        "    # Normalize submission location for Kaggle\n",
        "    cand = list(Path(\".\").rglob(\"submission.csv\"))\n",
        "    if cand:\n",
        "        dest = Path(\"/kaggle/working/submission.csv\") if IS_KAGGLE else (WORK / \"submission.csv\")\n",
        "        shutil.copy2(cand[0], dest)\n",
        "        print(f\"Copied {cand[0]} â†’ {dest}\")\n",
        "    else:\n",
        "        print(\"WARNING: submission.csv not found â€” check your predict output path.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Stage: Diagnose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if DO_DIAGNOSE:\n",
        "    banner(\"Stage: Diagnose\")\n",
        "    if USE_CLI:\n",
        "        cmd = [sys.executable, \"-m\", \"spectramind\", \"diagnose\"] + HYDRA_OVERRIDES\n",
        "        times[\"diagnose\"] = run_cmd(cmd)\n",
        "    else:\n",
        "        from spectramind.pipeline import diagnostics\n",
        "        t0 = time.time()\n",
        "        diagnostics.run(config_name=\"diagnose\", overrides=HYDRA_OVERRIDES)\n",
        "        times[\"diagnose\"] = time.time() - t0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Stage: Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if DO_PACKAGE:\n",
        "    banner(\"Stage: Package\")\n",
        "    # Ensure submission.csv exists before zipping\n",
        "    sub_csv = Path(\"/kaggle/working/submission.csv\") if IS_KAGGLE else (WORK / \"submission.csv\")\n",
        "    assert sub_csv.exists(), f\"submission.csv not found at {sub_csv}; run predict first.\"\n",
        "    out_zip = (WORK / \"submission.zip\")\n",
        "    overrides = HYDRA_OVERRIDES + [f\"submit.out_zip={out_zip}\", f\"submit.csv={sub_csv}\"]\n\n",
        "    if USE_CLI:\n",
        "        cmd = [sys.executable, \"-m\", \"spectramind\", \"submit\"] + overrides\n",
        "        times[\"package\"] = run_cmd(cmd)\n",
        "    else:\n",
        "        from spectramind.pipeline import submit\n",
        "        t0 = time.time()\n",
        "        submit.run(config_name=\"submit\", overrides=overrides)\n",
        "        times[\"package\"] = time.time() - t0\n\n",
        "    print(\"Packaged:\", out_zip, \"exists:\", out_zip.exists())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) Quick submission preview & summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "banner(\"Validate submission & Summary\")\n\n",
        "sub = Path(\"/kaggle/working/submission.csv\") if IS_KAGGLE else (WORK / \"submission.csv\")\n",
        "if sub.exists():\n",
        "    print(\"submission.csv:\", sub)\n",
        "    try:\n",
        "        # lightweight preview\n",
        "        import pandas as pd\n",
        "        df = pd.read_csv(sub)\n",
        "        print(df.head(3))\n",
        "        print(\"rows:\", len(df), \"| columns:\", list(df.columns))\n",
        "    except Exception as e:\n",
        "        print(\"Loaded submission as text (pandas unavailable):\")\n",
        "        print(sub.read_text().splitlines()[:5])\n\n",
        "summary = {\n",
        "    \"stages\": {k: sec(v) for k, v in times.items()},\n",
        "    \"paths\": {\n",
        "        \"repo_root\": str(REPO_ROOT), \"data_root\": str(DATA_ROOT),\n",
        "        \"work\": str(WORK), \"submission_csv\": str(sub),\n",
        "        \"submission_zip\": str((WORK / \"submission.zip\")),\n",
        "    },\n",
        "    \"fast_mode\": FAST_MODE, \"seed\": SEED, \"use_cli\": USE_CLI,\n",
        "}\n",
        "with open(OUT / \"run_summary.json\", \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "print(\"\\nRun summary:\", json.dumps(summary, indent=2))\n",
        "print(\"\\nAll done â€” use Kaggleâ€™s Submit button (it reads /kaggle/working/submission.csv).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### Notes\n",
        "- If your repository hasnâ€™t separated preprocess from calibrate yet, keep `DO_PREPROCESS=False`.\n",
        "- If your predict stage expects a different override key for the checkpoint, adjust the `predict.ckpt` override accordingly.\n",
        "- For inference-only kernels: set `DO_TRAIN=False`, attach a checkpoint dataset, and the notebook will auto-discover the latest `*.ckpt`/`*.pth`.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
