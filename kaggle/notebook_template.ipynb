{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd8fb016",
   "metadata": {},
   "source": [
    "# SpectraMind V50 — Kaggle Notebook Template\n",
    "\n",
    "**Purpose**: a safe, reproducible scaffold for running the NeurIPS 2025 Ariel Data Challenge\n",
    "workflows on Kaggle without internet access.\n",
    "\n",
    "This template supports:\n",
    "- Environment detection (Kaggle vs local)\n",
    "- Read-only data access at `/kaggle/input`\n",
    "- Optional import of the SpectraMind V50 package if it is available as a Kaggle dataset\n",
    "- Strict, pinned deps preferred (see `requirements-kaggle.txt` in the repo)\n",
    "- Reproducible config snapshot embedded in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62c6f5c",
   "metadata": {},
   "source": [
    "## 0) Environment & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c0e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, platform\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "IS_KAGGLE = Path('/kaggle/input').exists()\n",
    "COMP_DIR = Path('/kaggle/input/ariel-data-challenge-2025') if IS_KAGGLE else Path('./data')\n",
    "print(\"Env:\", \"Kaggle\" if IS_KAGGLE else \"Local\", \"| Python:\", sys.version.split()[0])\n",
    "\n",
    "# Optional: repo-attached dataset with installed package (no internet)\n",
    "SPECTRAMIND_DS = Path('/kaggle/input/spectramind-v50')\n",
    "if IS_KAGGLE and SPECTRAMIND_DS.exists():\n",
    "    sys.path.insert(0, str(SPECTRAMIND_DS / 'src'))\n",
    "    print(\"SpectraMind source path added:\", SPECTRAMIND_DS/'src')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29259185",
   "metadata": {},
   "source": [
    "## 1) Config Snapshot (embed minimal JSON for provenance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a6d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store a minimal config snapshot for reproducibility\n",
    "config = {\n",
    "    \"pipeline\": [\"calibrate\", \"predict\"],\n",
    "    \"model\": {\n",
    "        \"fgs1_encoder\": \"mamba_ssm-lite\",\n",
    "        \"airs_encoder\": \"cnn-lite\",\n",
    "        \"decoder\": \"heteroscedastic-head\"\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"competition\": str(COMP_DIR),\n",
    "        \"bins\": 283\n",
    "    },\n",
    "    \"runtime\": {\n",
    "        \"env\": \"kaggle\" if IS_KAGGLE else \"local\",\n",
    "        \"python\": platform.python_version()\n",
    "    }\n",
    "}\n",
    "config_path = Path('outputs'); config_path.mkdir(exist_ok=True, parents=True)\n",
    "with open(config_path/'config_snapshot.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "print(\"Wrote:\", config_path/'config_snapshot.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a3ff96",
   "metadata": {},
   "source": [
    "## 2) Data Access (read competition files if present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852d154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(base: Path, patterns=('.csv', '.parquet', '.json')):\n",
    "    if not base.exists():\n",
    "        return []\n",
    "    out = []\n",
    "    for p in base.rglob('*'):\n",
    "        if p.suffix.lower() in patterns:\n",
    "            out.append(str(p))\n",
    "    return sorted(out)[:50]\n",
    "\n",
    "inventory = list_files(COMP_DIR)\n",
    "print(\"Sample files:\", len(inventory))\n",
    "for p in inventory[:10]:\n",
    "    print(\"-\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f34c40",
   "metadata": {},
   "source": [
    "## 3) Minimal EDA (guarded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde2589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: try to read train.csv / test.csv if they exist\n",
    "def safe_read_csv(p: Path, n=5):\n",
    "    try:\n",
    "        df = pd.read_csv(p)\n",
    "        print(p.name, df.shape)\n",
    "        display(df.head(n))\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(\"Failed reading\", p, \"->\", e)\n",
    "\n",
    "train_csv = COMP_DIR/'train.csv'\n",
    "test_csv  = COMP_DIR/'test.csv'\n",
    "train_df = safe_read_csv(train_csv) if train_csv.exists() else None\n",
    "test_df  = safe_read_csv(test_csv) if test_csv.exists() else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acd1473",
   "metadata": {},
   "source": [
    "## 4) Optional: Import SpectraMind and Run Inference Hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c534713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the SpectraMind V50 package is available (attached as a Kaggle dataset), try to import a predict hook\n",
    "try:\n",
    "    from spectramind.cli_hooks import notebook_predict\n",
    "    HAVE_SM = True\n",
    "    print(\"SpectraMind hooks available.\")\n",
    "except Exception as e:\n",
    "    HAVE_SM = False\n",
    "    print(\"SpectraMind hooks not available:\", e)\n",
    "\n",
    "# Inference stub (replace IDs/source as needed)\n",
    "sample_ids = None\n",
    "if test_df is not None and 'id' in test_df.columns:\n",
    "    sample_ids = test_df['id'].head(5).tolist()\n",
    "\n",
    "if HAVE_SM:\n",
    "    # This function should emit a DataFrame with columns: id, mu_000.., sigma_000..\n",
    "    preds = notebook_predict(\n",
    "        comp_dir=str(COMP_DIR),\n",
    "        config=config,\n",
    "        ids=sample_ids\n",
    "    )\n",
    "    display(preds.head())\n",
    "    out_csv = Path('outputs')/'submission.csv'\n",
    "    preds.to_csv(out_csv, index=False)\n",
    "    print(\"Wrote submission to\", out_csv)\n",
    "else:\n",
    "    print(\"No spectramind package — keeping the template minimal. \"\n",
    "          \"You can add a cell to generate a dummy submission matching the schema.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f0dad7",
   "metadata": {},
   "source": [
    "## 5) Submission Packaging Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d9cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tiny helper to validate/schema-check and zip the submission, if desired.\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "def zip_submission(csv_path: Path, zip_path: Path):\n",
    "    assert csv_path.exists(), \"CSV not found\"\n",
    "    with zipfile.ZipFile(zip_path, mode='w', compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "        zf.write(csv_path, arcname=csv_path.name)\n",
    "    print(\"Created:\", zip_path)\n",
    "\n",
    "sub = Path('outputs')/'submission.csv'\n",
    "if sub.exists():\n",
    "    zip_submission(sub, Path('submission.zip'))\n",
    "else:\n",
    "    print(\"No submission.csv found — skip zipping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32dd460",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- **No internet**: this notebook avoids `pip install` and assumes dependencies come from attached datasets / Kaggle image.\n",
    "- **Reproducibility**: we snapshot a minimal config in `outputs/config_snapshot.json`; extend as needed.\n",
    "- **Importing SpectraMind**: If you publish your repo as a Kaggle Dataset containing `src/spectramind`, this template will auto-import.\n",
    "- **Schema**: ensure your submission matches the challenge schema (283 μ, 283 σ bins).\n",
    "- **Runtime**: keep cell runtimes reasonable (Kaggle typical limit ≤9h)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
