{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a24a2333",
   "metadata": {},
   "source": [
    "\n",
    "# SpectraMind V50 — Model Ablation Study\n",
    "\n",
    "This notebook runs **systematic ablations** over the SpectraMind V50 architecture and loss stack to quantify each component’s contribution.\n",
    "\n",
    "**Scope**\n",
    "- Encoders: FGS1 (temporal) / AIRS (spectral)\n",
    "- Fusion: concatenation vs. cross-attn (or SSM gating)\n",
    "- Decoder heads: μ/σ joint vs. decoupled\n",
    "- Loss stack: Gaussian NLL (base) + smoothness + non-negativity + band coherence + calibration\n",
    "- Precision / mixed precision\n",
    "- Training-time toggles (early stopping, lr scheduler)\n",
    "\n",
    "**Outputs**\n",
    "- CSV of runs & metrics\n",
    "- Plots comparing ablated configs\n",
    "- A short, printable summary\n",
    "\n",
    "> Tip: This notebook calls the project CLI (`spectramind`) or Python entrypoints. Ensure your repo is installed (editable mode) in this kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fc5112",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Environment sanity check (customize paths if needed) ---\n",
    "import sys, subprocess, json, os, shutil, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print('Python:', sys.version)\n",
    "print('CWD:', os.getcwd())\n",
    "\n",
    "# Try to import project; fall back to CLI calls if not importable\n",
    "try:\n",
    "    import spectramind\n",
    "    HAS_PACKAGE = True\n",
    "    print('spectramind package found:', spectramind.__version__ if hasattr(spectramind, '__version__') else 'OK')\n",
    "except Exception as e:\n",
    "    HAS_PACKAGE = False\n",
    "    print('spectramind package not importable:', e)\n",
    "\n",
    "# CLI resolver\n",
    "def run_cli(args, capture_output=True, check=False):\n",
    "    \"\"\"Run a spectramind CLI command. Returns (rc, stdout, stderr).\"\"\"\n",
    "    if shutil.which('spectramind'):\n",
    "        cmd = ['spectramind'] + args\n",
    "    else:\n",
    "        cmd = [sys.executable, '-m', 'spectramind'] + args\n",
    "    print('> ', ' '.join(map(str, cmd)))\n",
    "    p = subprocess.run(cmd, capture_output=capture_output, text=True)\n",
    "    if check and p.returncode != 0:\n",
    "        raise RuntimeError(p.stderr or p.stdout)\n",
    "    return p.returncode, p.stdout, p.stderr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed015a4",
   "metadata": {},
   "source": [
    "## 1) Define ablation grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a979024",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a compact ablation grid. Keep runs short by using debug/truncated configs.\n",
    "# Each entry is a dict of Hydra overrides.\n",
    "ABLATIONS = [\n",
    "    # Baseline\n",
    "    {'name':'baseline', 'overrides':[\n",
    "        '+env=local', '+data=nominal', '+calib=nominal', '+model=v50',\n",
    "        '+training=lightning', '+loss=composite', '+logger=csv'\n",
    "    ]},\n",
    "    # Remove smoothness\n",
    "    {'name':'no_smooth', 'overrides':[\n",
    "        '+loss.composite.enable_smoothness=false'\n",
    "    ]},\n",
    "    # Remove non-negativity constraint\n",
    "    {'name':'no_nonneg', 'overrides':[\n",
    "        '+loss.composite.enable_nonneg=false'\n",
    "    ]},\n",
    "    # Remove band coherence\n",
    "    {'name':'no_bandcoh', 'overrides':[\n",
    "        '+loss.composite.enable_band_coherence=false'\n",
    "    ]},\n",
    "    # FGS1 encoder ablation: simpler MLP\n",
    "    {'name':'fgs1_mlp', 'overrides':[\n",
    "        '+model.fgs1_encoder=mlp_small'\n",
    "    ]},\n",
    "    # AIRS encoder ablation: shallow CNN\n",
    "    {'name':'airs_cnn_shallow', 'overrides':[\n",
    "        '+model.airs_encoder=cnn_shallow'\n",
    "    ]},\n",
    "    # Fusion change: concat -> cross-attn (if available)\n",
    "    {'name':'fusion_xattn', 'overrides':[\n",
    "        '+model.fusion=attn'\n",
    "    ]},\n",
    "    # Decoder heads decoupled μ/σ\n",
    "    {'name':'decoupled_heads', 'overrides':[\n",
    "        '+model.decoder.decoupled=true'\n",
    "    ]},\n",
    "    # Precision ablation\n",
    "    {'name':'amp_off', 'overrides':[\n",
    "        '+training.precision.precision=32'\n",
    "    ]},\n",
    "]\n",
    "\n",
    "# Optionally shrink training budget for quick sweeps\n",
    "GLOBAL_OVERRIDES = [\n",
    "    '+training.max_epochs=3',\n",
    "    '+training.trainer.limit_train_batches=0.2',\n",
    "    '+training.trainer.limit_val_batches=1.0',\n",
    "    '+logger.csv.dir=artifacts/ablations'\n",
    "]\n",
    "\n",
    "print(f'{len(ABLATIONS)} ablations configured.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d2049e",
   "metadata": {},
   "source": [
    "## 2) Run ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cc0c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "RESULTS = []\n",
    "ARTIFACT_DIR = Path('artifacts/ablations')\n",
    "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def run_one(ablation):\n",
    "    name = ablation['name']\n",
    "    overrides = ablation.get('overrides', [])\n",
    "    hydra_args = ['train', '--config-name', 'train'] + [*GLOBAL_OVERRIDES, *overrides]\n",
    "    started = time.time()\n",
    "    try:\n",
    "        rc, out, err = run_cli(hydra_args, capture_output=True, check=False)\n",
    "        elapsed = time.time() - started\n",
    "        # Try to parse metrics if the CLI prints JSON lines or write a metrics file\n",
    "        # Here we heuristically search the CSV logger directory for the latest metrics.csv\n",
    "        metrics_path = None\n",
    "        if ARTIFACT_DIR.exists():\n",
    "            candidates = sorted(ARTIFACT_DIR.rglob('metrics*.csv'), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "            metrics_path = str(candidates[0]) if candidates else None\n",
    "        RESULTS.append({\n",
    "            'name': name,\n",
    "            'returncode': rc,\n",
    "            'elapsed_sec': round(elapsed, 2),\n",
    "            'metrics_csv': metrics_path,\n",
    "            'stdout_tail': (out or '')[-800:],\n",
    "            'stderr_tail': (err or '')[-800:]\n",
    "        })\n",
    "    except Exception as ex:\n",
    "        elapsed = time.time() - started\n",
    "        RESULTS.append({\n",
    "            'name': name,\n",
    "            'returncode': -1,\n",
    "            'elapsed_sec': round(elapsed, 2),\n",
    "            'metrics_csv': None,\n",
    "            'error': str(ex)\n",
    "        })\n",
    "\n",
    "# Toggle this to actually run (set to False when editing)\n",
    "EXECUTE = False\n",
    "\n",
    "if EXECUTE:\n",
    "    for abl in ABLATIONS:\n",
    "        print(f'\\n=== Running: {abl[\"name\"]} ===')\n",
    "        run_one(abl)\n",
    "\n",
    "pd.DataFrame(RESULTS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21bc2bc",
   "metadata": {},
   "source": [
    "## 3) Aggregate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74539a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_metrics_row(row):\n",
    "    path = row.get('metrics_csv')\n",
    "    if not path or not os.path.exists(path):\n",
    "        return {}\n",
    "    try:\n",
    "        dfm = pd.read_csv(path)\n",
    "        # assume last row is the final epoch/validation metrics\n",
    "        last = dfm.iloc[-1].to_dict()\n",
    "        # keep only common keys\n",
    "        keep = {k: v for k, v in last.items() if any(x in k for x in ['val_', 'epoch', 'gll', 'loss'])}\n",
    "        return keep\n",
    "    except Exception as e:\n",
    "        return {'metrics_error': str(e)}\n",
    "\n",
    "if RESULTS:\n",
    "    df = pd.DataFrame(RESULTS)\n",
    "    metric_cols = []\n",
    "    expanded = []\n",
    "    for _, r in df.iterrows():\n",
    "        m = load_metrics_row(r)\n",
    "        rr = dict(r)\n",
    "        rr.update(m)\n",
    "        expanded.append(rr)\n",
    "        metric_cols += list(m.keys())\n",
    "    df_exp = pd.DataFrame(expanded)\n",
    "    metric_cols = sorted(set(metric_cols))\n",
    "    display(df_exp[['name','returncode','elapsed_sec'] + metric_cols])\n",
    "else:\n",
    "    print('No RESULTS yet. Set EXECUTE=True to run.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a9fd08",
   "metadata": {},
   "source": [
    "## 4) Plot comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5566d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 'df_exp' in globals():\n",
    "    key = None\n",
    "    # Heuristic: choose a known metric name if present\n",
    "    for k in ['val_gll', 'val_loss', 'val_metric']:\n",
    "        if k in df_exp.columns:\n",
    "            key = k\n",
    "            break\n",
    "    if key:\n",
    "        plt.figure(figsize=(8,4))\n",
    "        df_plot = df_exp.sort_values(key)\n",
    "        plt.barh(df_plot['name'], df_plot[key])\n",
    "        plt.xlabel(key)\n",
    "        plt.title('Ablation Comparison')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('No recognized validation metric column found to plot.')\n",
    "else:\n",
    "    print('No aggregated DataFrame available.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b6b6c8",
   "metadata": {},
   "source": [
    "## 5) Generate summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759fb802",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SUMMARY_PATH = ARTIFACT_DIR / 'ablation_summary.csv'\n",
    "if 'df_exp' in globals():\n",
    "    df_exp.to_csv(SUMMARY_PATH, index=False)\n",
    "    print('Saved summary to', SUMMARY_PATH)\n",
    "else:\n",
    "    print('Nothing to summarize yet.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22561a8",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Appendix: Notes\n",
    "\n",
    "- The ablation overrides assume corresponding Hydra config groups:\n",
    "  - `+model.fgs1_encoder=mlp_small`, `+model.airs_encoder=cnn_shallow`, `+model.fusion=attn`, etc.\n",
    "  - `+loss.composite.enable_*` boolean flags within the loss stack.\n",
    "- Swap `+env=local` for `+env=kaggle` when running on Kaggle.\n",
    "- Increase `+training.max_epochs` for high-fidelity results; this notebook defaults to quick smoke tests.\n",
    "- If you don’t have the package importable, ensure the CLI works (`pip install -e .` or `python -m spectramind --help`).\n",
    "\n",
    "**Suggested metrics to track** (and ensure your logger emits them as CSV columns):\n",
    "- `val_gll` (Gaussian log-likelihood, higher is better or negate if using loss convention)\n",
    "- `val_loss` (lower is better)\n",
    "- `val_smooth_penalty`, `val_nonneg_violations`, `val_band_coherence` (diagnostic)\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
