{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpectraMind V50 — Kaggle **Training** Notebook\n",
    "\n",
    "**Purpose:** train the SpectraMind V50 model **inside Kaggle** (no internet).  \n",
    "Attach the Ariel competition dataset and your SpectraMind V50 code dataset (and optionally an **artifacts** dataset with checkpoints).  \n",
    "\n",
    "> Keep this notebook lightweight; heavy preprocessing/training should live in library code & DVC stages. This scaffold ensures safe defaults and reproducible snapshots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 0) Environment & Inputs"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, platform, shutil, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Determinism\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "IS_KAGGLE = Path('/kaggle/input').exists()\n",
    "COMP_DIR = Path('/kaggle/input/ariel-data-challenge-2025') if IS_KAGGLE else Path('./data/kaggle-mock')\n",
    "CODE_DS  = Path('/kaggle/input/spectramind-v50') if IS_KAGGLE else Path('./')  # attached code dataset\n",
    "\n",
    "print(\"Env:\", \"Kaggle\" if IS_KAGGLE else \"Local\", \"| Python:\", sys.version.split()[0])\n",
    "print(\"Competition data:\", COMP_DIR.exists(), str(COMP_DIR))\n",
    "\n",
    "# Outputs / Artifacts\n",
    "OUT = Path('outputs'); OUT.mkdir(parents=True, exist_ok=True)\n",
    "ART = Path('artifacts'); ART.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Add spectramind src path if code dataset is attached\n",
    "if IS_KAGGLE and (CODE_DS/'src').exists():\n",
    "    sys.path.insert(0, str(CODE_DS/'src'))\n",
    "    print(\"Added code src path:\", CODE_DS/'src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### (Optional) Symlink Kaggle inputs into repo layout (runtime mounts)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to map Kaggle input data into a repo-style data layout (zero-copy)\n",
    "# %%bash\n",
    "# REPO=/kaggle/working/spectramind-v50\n",
    "# mkdir -p \"$REPO/data/raw\" \"$REPO/data/interim\" \"$REPO/data/processed\" \"$REPO/data/external\" \"$REPO/artifacts\" \"$REPO/models\"\n",
    "# ln -sfn /kaggle/input/ariel-data-challenge-2025  \"$REPO/data/raw/adc2025\"\n",
    "# echo \"Symlinked Kaggle inputs under $REPO/data/raw/adc2025\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 1) GPU / Torch Check (guarded)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "    print(\"PyTorch:\", torch.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "except Exception as e:\n",
    "    print(\"Torch not available / skipped:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 2) Minimal Config Snapshot (Hydra-like)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"env\": \"kaggle\" if IS_KAGGLE else \"local\",\n",
    "    \"data\": {\n",
    "        \"competition_dir\": str(COMP_DIR),\n",
    "        \"train_csv\": str(COMP_DIR/'train.csv'),\n",
    "        \"train_star_info\": str(COMP_DIR/'train_star_info.csv'),\n",
    "        \"axis_info\": str(COMP_DIR/'axis_info.parquet')\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"seed\": SEED,\n",
    "        \"epochs\": 5,            # keep light for Kaggle; increase in real runs\n",
    "        \"batch_size\": 32,\n",
    "        \"lr\": 1e-3,\n",
    "        \"precision\": \"fp32\",     # set \"bf16\"/\"fp16\" only if supported\n",
    "        \"grad_accum\": 1,\n",
    "        \"save_dir\": \"artifacts\"\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"name\": \"v50\",\n",
    "        \"fgs1_encoder\": \"mamba_ssm-lite\",\n",
    "        \"airs_encoder\": \"cnn-lite\",\n",
    "        \"decoder\": \"heteroscedastic-head\"\n",
    "    }\n",
    "}\n",
    "with open(OUT/'config_snapshot.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "print(\"Wrote\", OUT/'config_snapshot.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 3) Fast Data Sanity (guarded)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(p):\n",
    "    try: return Path(p).exists()\n",
    "    except Exception: return False\n",
    "\n",
    "issues = []\n",
    "if not exists(config[\"data\"][\"train_csv\"]):\n",
    "    issues.append(\"Missing train.csv\")\n",
    "if not exists(config[\"data\"][\"axis_info\"]):\n",
    "    issues.append(\"Missing axis_info.parquet (optional)\")\n",
    "print(\"Issues:\", issues if issues else \"None\")\n",
    "\n",
    "# Head preview to keep runs light\n",
    "if not issues and Path(config[\"data\"][\"train_csv\"]).exists():\n",
    "    try:\n",
    "        df = pd.read_csv(config[\"data\"][\"train_csv\"], nrows=5)\n",
    "        print(\"train.csv:\", df.shape)\n",
    "        display(df.head(3))\n",
    "    except Exception as e:\n",
    "        print(\"train.csv read error:\", e)\n",
    "else:\n",
    "    print(\"train.csv not available — continuing (hooks may load differently)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 4) Import SpectraMind hooks (if available)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Expected: returns (checkpoint_path, metrics_dict)\n",
    "    from spectramind.cli_hooks import notebook_train\n",
    "    HAVE_SM = True\n",
    "    print(\"SpectraMind hooks available.\")\n",
    "except Exception as e:\n",
    "    HAVE_SM = False\n",
    "    print(\"SpectraMind hooks NOT available:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 5) Train (hook or demo)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = None\n",
    "metrics = {}\n",
    "\n",
    "if HAVE_SM:\n",
    "    # Preferred path: delegate to package hook (should do all preprocessing + training)\n",
    "    t0 = time.time()\n",
    "    ckpt_path, metrics = notebook_train(config=config)\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"Hook training finished in {elapsed:.1f}s\")\n",
    "    print(\"Checkpoint:\", ckpt_path)\n",
    "    print(\"Metrics:\", metrics)\n",
    "else:\n",
    "    print(\"Falling back to a tiny demo trainer (placeholder)\")\n",
    "    # --- Demo: simulate a training artifact ---\n",
    "    t0 = time.time()\n",
    "    time.sleep(1.0)\n",
    "    ckpt_path = str((Path(config[\"training\"][\"save_dir\"]) / 'model_v50_demo.ckpt').resolve())\n",
    "    Path(config[\"training\"][\"save_dir\"]).mkdir(parents=True, exist_ok=True)\n",
    "    with open(ckpt_path, 'wb') as f:\n",
    "        f.write(os.urandom(256))\n",
    "    metrics = {\"train_loss\": 0.123, \"val_loss\": 0.234, \"elapsed_s\": round(time.time()-t0, 2)}\n",
    "    with open(OUT/'train_metrics.json', 'w') as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    print(\"Saved demo checkpoint:\", ckpt_path)\n",
    "    print(\"Metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 6) Register Artifacts (manifest)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = {\n",
    "    \"checkpoint\": ckpt_path,\n",
    "    \"metrics\": metrics,\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "}\n",
    "with open(OUT/'train_manifest.json', 'w') as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "print(\"Wrote\", OUT/'train_manifest.json')\n",
    "print(\"\\nTraining complete. Next: use this checkpoint in your prediction notebook to build submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- **Zero internet**: all deps must come from the Kaggle base image or attached datasets.\n",
    "- **Reproducibility**: config snapshot at `outputs/config_snapshot.json` and metrics at `outputs/train_metrics.json` (demo) or returned by your hook.\n",
    "- **Data**: competition files live under `/kaggle/input/ariel-data-challenge-2025/`; use symlinks under `/kaggle/working/.../data/...` for repo-style paths (runtime-only mounts).\n",
    "- **Runtime**: keep epochs small in notebooks; long runs belong in offline/CLI pipelines. Control seeds; pin dependencies via a Kaggle-ready `requirements` dataset if you need custom packages."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
