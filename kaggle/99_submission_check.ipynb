{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ec097c",
   "metadata": {},
   "source": [
    "\n",
    "# SpectraMind V50 — Submission Checker (Ariel 2025)\n",
    "\n",
    "This notebook validates a **Kaggle submission** for the NeurIPS 2025 Ariel Data Challenge.\n",
    "\n",
    "It performs:\n",
    "- **Schema checks**: required columns, count (283 μ, 283 σ), dtypes, missing/NaN, order (optional).\n",
    "- **Value checks**: finiteness, σ ≥ 0, configurable bounds on μ and σ, outlier and NaN counts.\n",
    "- **File checks**: size, memory, duplicate ids, row count.\n",
    "- **Visual QA**: random spectrum plots with μ±σ, histograms and percentiles.\n",
    "- **Report**: machine-readable summary (CSV/JSON) with pass/fail and metrics.\n",
    "\n",
    "> You can set a path to `submission.csv` or point to a `.zip` containing it. Defaults to `artifacts/submission.csv`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b512f07",
   "metadata": {},
   "source": [
    "## 0) Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f884ed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Path to CSV or ZIP\n",
    "SUBMISSION_PATH = Path('artifacts/submission.csv')  # change if needed\n",
    "\n",
    "# Expected schema\n",
    "N_BINS = 283\n",
    "ID_COL = 'id'\n",
    "MU_PREFIX = 'mu_'\n",
    "SIGMA_PREFIX = 'sigma_'\n",
    "\n",
    "# Soft bounds (challenge-specific; keep permissive by default)\n",
    "MU_ABS_MAX = 1.0           # transit depth magnitude (fraction). Set None to disable.\n",
    "SIGMA_ABS_MAX = 1.0        # Set None to disable.\n",
    "\n",
    "# Random seed for plots\n",
    "SEED = 42\n",
    "\n",
    "SUBMISSION_PATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fdc689",
   "metadata": {},
   "source": [
    "## 1) Load submission (CSV or ZIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b58a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd, numpy as np, zipfile, io, json, math, time\n",
    "from pathlib import Path\n",
    "\n",
    "def load_submission(path: Path) -> pd.DataFrame:\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f'Not found: {path}')\n",
    "    if path.suffix.lower() == '.zip':\n",
    "        with zipfile.ZipFile(path, 'r') as zf:\n",
    "            # Try standard filenames\n",
    "            names = zf.namelist()\n",
    "            cand = None\n",
    "            for nm in names:\n",
    "                if nm.lower().endswith('submission.csv') or nm.lower().endswith('.csv'):\n",
    "                    cand = nm; break\n",
    "            if cand is None:\n",
    "                raise ValueError(f'No CSV file found inside zip ({len(names)} entries).')\n",
    "            with zf.open(cand) as f:\n",
    "                return pd.read_csv(f)\n",
    "    else:\n",
    "        return pd.read_csv(path)\n",
    "\n",
    "df = load_submission(SUBMISSION_PATH)\n",
    "print('Loaded:', df.shape)\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4febc8",
   "metadata": {},
   "source": [
    "## 2) Build expected column list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a650ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def expected_columns(n_bins=283, id_col='id', mu_prefix='mu_', sigma_prefix='sigma_'):\n",
    "    mu_cols = [f\"{mu_prefix}{i:03d}\" for i in range(n_bins)]\n",
    "    sg_cols = [f\"{sigma_prefix}{i:03d}\" for i in range(n_bins)]\n",
    "    return [id_col] + mu_cols + sg_cols\n",
    "\n",
    "exp_cols = expected_columns(N_BINS, ID_COL, MU_PREFIX, SIGMA_PREFIX)\n",
    "print('Expected column count:', len(exp_cols))\n",
    "print('First 6:', exp_cols[:6], '...', 'Last 6:', exp_cols[-6:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb0c218",
   "metadata": {},
   "source": [
    "## 3) Schema validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "schema_report = {}\n",
    "\n",
    "# Column presence (set equality, order optional)\n",
    "have_cols = list(df.columns)\n",
    "missing = [c for c in exp_cols if c not in df.columns]\n",
    "extra = [c for c in df.columns if c not in exp_cols]\n",
    "\n",
    "schema_report['missing_columns'] = missing\n",
    "schema_report['extra_columns'] = extra\n",
    "schema_report['has_all_required'] = len(missing) == 0\n",
    "schema_report['column_count'] = len(df.columns)\n",
    "schema_report['row_count'] = len(df)\n",
    "\n",
    "# Optional: warn if order differs\n",
    "schema_report['order_matches'] = (have_cols == exp_cols)\n",
    "\n",
    "# dtypes check for numeric columns\n",
    "num_cols = [c for c in exp_cols if c != ID_COL]\n",
    "non_numeric = [c for c in num_cols if not pd.api.types.is_numeric_dtype(df[c])]\n",
    "schema_report['non_numeric_value_columns'] = non_numeric\n",
    "\n",
    "# id uniqueness/non-null\n",
    "id_null = int(df[ID_COL].isna().sum()) if ID_COL in df.columns else -1\n",
    "id_dups = int(df[ID_COL].duplicated().sum()) if ID_COL in df.columns else -1\n",
    "schema_report['id_null_count'] = id_null\n",
    "schema_report['id_duplicate_count'] = id_dups\n",
    "\n",
    "schema_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9091896",
   "metadata": {},
   "source": [
    "## 4) Value checks (NaN, finite, bounds, σ≥0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90efce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_report = {}\n",
    "issues = []\n",
    "\n",
    "# NaN / infinite\n",
    "if schema_report.get('has_all_required', False):\n",
    "    mu_cols = [c for c in df.columns if c.startswith(MU_PREFIX)]\n",
    "    sg_cols = [c for c in df.columns if c.startswith(SIGMA_PREFIX)]\n",
    "else:\n",
    "    mu_cols = [c for c in df.columns if c.startswith(MU_PREFIX)]\n",
    "    sg_cols = [c for c in df.columns if c.startswith(SIGMA_PREFIX)]\n",
    "\n",
    "def count_nonfinite(series):\n",
    "    s = series.to_numpy()\n",
    "    return int(np.sum(~np.isfinite(s)))\n",
    "\n",
    "val_report['mu_nan_count'] = int(df[mu_cols].isna().sum().sum()) if mu_cols else -1\n",
    "val_report['sigma_nan_count'] = int(df[sg_cols].isna().sum().sum()) if sg_cols else -1\n",
    "val_report['mu_nonfinite_count'] = sum(count_nonfinite(df[c]) for c in mu_cols) if mu_cols else -1\n",
    "val_report['sigma_nonfinite_count'] = sum(count_nonfinite(df[c]) for c in sg_cols) if sg_cols else -1\n",
    "\n",
    "# Sigma >= 0\n",
    "if sg_cols:\n",
    "    sigma_neg = int((df[sg_cols] < 0).sum().sum())\n",
    "else:\n",
    "    sigma_neg = -1\n",
    "val_report['sigma_negative_count'] = sigma_neg\n",
    "if sigma_neg > 0:\n",
    "    issues.append(f\"Found {sigma_neg} negative sigma values.\")\n",
    "\n",
    "# Soft bounds\n",
    "def count_out_of_bounds(frame, abs_max):\n",
    "    if abs_max is None: return 0\n",
    "    arr = np.abs(frame.to_numpy())\n",
    "    return int((arr > abs_max).sum())\n",
    "\n",
    "val_report['mu_out_of_bounds'] = count_out_of_bounds(df[mu_cols], MU_ABS_MAX) if mu_cols else -1\n",
    "val_report['sigma_out_of_bounds'] = count_out_of_bounds(df[sg_cols], SIGMA_ABS_MAX) if sg_cols else -1\n",
    "\n",
    "val_report['issues'] = issues\n",
    "val_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b853f7ce",
   "metadata": {},
   "source": [
    "## 5) Aggregates & percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c09e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agg = {}\n",
    "if 'mu_cols' in locals() and mu_cols and sg_cols:\n",
    "    mu_vals = df[mu_cols].to_numpy().ravel()\n",
    "    sg_vals = df[sg_cols].to_numpy().ravel()\n",
    "    for name, arr in [('mu', mu_vals), ('sigma', sg_vals)]:\n",
    "        clean = arr[np.isfinite(arr)]\n",
    "        q = np.quantile(clean, [0, .001, .01, .05, .5, .95, .99, .999, 1.0])\n",
    "        agg[f'{name}_min'] = float(q[0])\n",
    "        agg[f'{name}_p001'] = float(q[1])\n",
    "        agg[f'{name}_p01'] = float(q[2])\n",
    "        agg[f'{name}_p05'] = float(q[3])\n",
    "        agg[f'{name}_median'] = float(q[4])\n",
    "        agg[f'{name}_p95'] = float(q[5])\n",
    "        agg[f'{name}_p99'] = float(q[6])\n",
    "        agg[f'{name}_p999'] = float(q[7])\n",
    "        agg[f'{name}_max'] = float(q[8])\n",
    "agg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c66b15",
   "metadata": {},
   "source": [
    "## 6) Visual QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c8516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def plot_random_spectra(df, n=3):\n",
    "    if not (mu_cols and sg_cols):\n",
    "        print('Missing expected mu/sigma columns; skip plots.')\n",
    "        return\n",
    "    idxs = random.sample(range(len(df)), min(n, len(df)))\n",
    "    xs = np.arange(len(mu_cols))\n",
    "    for i in idxs:\n",
    "        row = df.iloc[i]\n",
    "        mu = row[mu_cols].to_numpy(dtype=float)\n",
    "        sg = row[sg_cols].to_numpy(dtype=float)\n",
    "        plt.figure(figsize=(9,3))\n",
    "        plt.plot(xs, mu, label='mu')\n",
    "        plt.fill_between(xs, mu - sg, mu + sg, alpha=0.2, label='mu ± sigma')\n",
    "        plt.title(f'id={row[ID_COL]} (row {i})')\n",
    "        plt.xlabel('bin')\n",
    "        plt.ylabel('transit depth')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def plot_hist(arr, title, bins=100, xlim=None):\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.hist(arr[np.isfinite(arr)], bins=bins, alpha=0.8)\n",
    "    if xlim is not None:\n",
    "        plt.xlim(*xlim)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if mu_cols and sg_cols:\n",
    "    plot_random_spectra(df, n=3)\n",
    "    mu_vals = df[mu_cols].to_numpy().ravel()\n",
    "    sg_vals = df[sg_cols].to_numpy().ravel()\n",
    "    plot_hist(mu_vals, 'Histogram: mu (all bins)',\n",
    "              xlim=(-MU_ABS_MAX, MU_ABS_MAX) if MU_ABS_MAX else None)\n",
    "    plot_hist(sg_vals, 'Histogram: sigma (all bins)',\n",
    "              xlim=(0, SIGMA_ABS_MAX) if SIGMA_ABS_MAX else None)\n",
    "else:\n",
    "    print('Skipping plots: mu/sigma columns not found.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea734f8",
   "metadata": {},
   "source": [
    "## 7) Pass/Fail & report export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32675377",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "REPORT_DIR = Path('artifacts/submission_checks')\n",
    "REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def make_pass_fail(schema_report, val_report):\n",
    "    ok = True\n",
    "    msgs = []\n",
    "    # Required schema\n",
    "    if not schema_report.get('has_all_required', False):\n",
    "        ok = False; msgs.append('Missing required columns.')\n",
    "    if schema_report.get('id_null_count', 0) > 0:\n",
    "        ok = False; msgs.append('Null IDs present.')\n",
    "    if schema_report.get('id_duplicate_count', 0) > 0:\n",
    "        ok = False; msgs.append('Duplicate IDs present.')\n",
    "    if schema_report.get('non_numeric_value_columns'):\n",
    "        ok = False; msgs.append('Non-numeric value columns detected.')\n",
    "    # Values\n",
    "    if val_report.get('sigma_negative_count', 0) > 0:\n",
    "        ok = False; msgs.append('Found negative sigma values.')\n",
    "    # Optional soft bounds\n",
    "    if MU_ABS_MAX is not None and val_report.get('mu_out_of_bounds', 0) > 0:\n",
    "        msgs.append('mu values exceed soft abs bound.')\n",
    "    if SIGMA_ABS_MAX is not None and val_report.get('sigma_out_of_bounds', 0) > 0:\n",
    "        msgs.append('sigma values exceed soft abs bound.')\n",
    "    return ok, msgs\n",
    "\n",
    "ok, messages = make_pass_fail(schema_report, val_report)\n",
    "summary = {\n",
    "    'timestamp': datetime.utcnow().isoformat() + 'Z',\n",
    "    'submission_path': str(SUBMISSION_PATH),\n",
    "    'row_count': schema_report.get('row_count'),\n",
    "    'column_count': schema_report.get('column_count'),\n",
    "    'pass': ok,\n",
    "    'messages': messages,\n",
    "    'schema_report': schema_report,\n",
    "    'value_report': val_report,\n",
    "    'aggregates': agg\n",
    "}\n",
    "\n",
    "# Save JSON and CSV-friendly flat summary\n",
    "json_path = REPORT_DIR / 'submission_check.json'\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "flat = {\n",
    "    'timestamp': summary['timestamp'],\n",
    "    'path': summary['submission_path'],\n",
    "    'rows': summary['row_count'],\n",
    "    'cols': summary['column_count'],\n",
    "    'pass': summary['pass'],\n",
    "    'missing_cols': len(schema_report.get('missing_columns', [])),\n",
    "    'extra_cols': len(schema_report.get('extra_columns', [])),\n",
    "    'id_null': schema_report.get('id_null_count', -1),\n",
    "    'id_dups': schema_report.get('id_duplicate_count', -1),\n",
    "    'mu_nan': val_report.get('mu_nan_count', -1),\n",
    "    'sigma_nan': val_report.get('sigma_nan_count', -1),\n",
    "    'mu_nonfinite': val_report.get('mu_nonfinite_count', -1),\n",
    "    'sigma_nonfinite': val_report.get('sigma_nonfinite_count', -1),\n",
    "    'sigma_negative': val_report.get('sigma_negative_count', -1),\n",
    "    'mu_oob': val_report.get('mu_out_of_bounds', -1),\n",
    "    'sigma_oob': val_report.get('sigma_out_of_bounds', -1),\n",
    "}\n",
    "pd.DataFrame([flat]).to_csv(REPORT_DIR / 'submission_check.csv', index=False)\n",
    "\n",
    "print('PASS' if ok else 'FAIL', '|', '; '.join(messages) if messages else 'OK')\n",
    "print('Saved report to:', json_path, 'and CSV twin in same folder.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57a46b2",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Appendix & Tips\n",
    "\n",
    "- **Expected columns**: `id`, followed by `mu_000..mu_282` and `sigma_000..sigma_282` (total 1+283+283 = 567 columns).\n",
    "- **σ must be non-negative** and finite; **μ** finite. You can relax/enforce soft bounds via `MU_ABS_MAX`/`SIGMA_ABS_MAX`.\n",
    "- If you package as `submission.zip`, ensure it **contains submission.csv at top level**.\n",
    "- Keep IDs unique; Kaggle evaluators may join on `id` and expect no duplicates.\n",
    "- For speed, replace pandas with polars if desired. For very large files, you can chunk-read and validate iteratively.\n",
    "- Integrate this notebook in CI to gate releases: emit a non-empty `messages` list to fail.\n",
    "\n",
    "**Common pitfalls**\n",
    "- Off-by-one in bin indexing (ensure zero-based, 3-digit padded).\n",
    "- Accidentally swapping μ and σ column groups.\n",
    "- Printing scientific notation strings to CSV instead of numeric dtypes (schema check flags non-numeric).\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
