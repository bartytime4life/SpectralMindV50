name: integration

on:
  push:
    branches: [main, develop]
    paths:
      - 'src/**'
      - 'configs/**'
      - 'schemas/**'
      - 'dvc.yaml'
      - 'dvc.lock'
      - 'scripts/**'
      - 'pyproject.toml'
      - 'requirements*.txt'
      - '.pre-commit-config.yaml'
      - '.github/workflows/integration.yml'
  pull_request:
    branches: [main, develop]
    paths:
      - 'src/**'
      - 'configs/**'
      - 'schemas/**'
      - 'dvc.yaml'
      - 'dvc.lock'
      - 'scripts/**'
      - 'pyproject.toml'
      - 'requirements*.txt'
      - '.pre-commit-config.yaml'
      - '.github/workflows/integration.yml'
  workflow_dispatch:

permissions:
  contents: read

concurrency:
  group: integration-${{ github.ref }}
  cancel-in-progress: true

env:
  PY_MAIN: '3.11'
  PY_MATRIX: '3.10,3.11,3.12'
  COVERAGE_FILE: .coverage
  PYTHONDONTWRITEBYTECODE: '1'
  PIP_DISABLE_PIP_VERSION_CHECK: '1'
  PIP_NO_PYTHON_VERSION_WARNING: '1'
  MPLBACKEND: 'Agg'
  # SpectraMind defaults for CI/Kaggle-safe runs
  SM_SUBMISSION_BINS: '283'
  SM_CI: '1'
  ARTIFACT_RETENTION_DAYS: '14'

jobs:
  lint:
    name: Ruff / Format / Pre-commit
    runs-on: ubuntu-latest
    timeout-minutes: 12
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PY_MAIN }}
          cache: 'pip'
          cache-dependency-path: |
            requirements*.txt
            pyproject.toml
            .pre-commit-config.yaml

      - name: Install lint deps
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi
          python -m pip install "ruff>=0.5,<1.0" "pre-commit>=3,<4"

      - name: Ruff format (check only)
        run: ruff format --check .

      - name: Ruff lint (github format)
        run: ruff check --output-format=github src/ tests/ configs/ || true

      - name: Pre-commit (selected hooks)
        if: hashFiles('.pre-commit-config.yaml') != ''
        run: pre-commit run --all-files --hook-stage manual --show-diff-on-failure

      - name: Summarize lint
        if: always()
        run: echo "### Lint completed (ruff + pre-commit)" >> $GITHUB_STEP_SUMMARY

  types:
    name: Type check (mypy)
    runs-on: ubuntu-latest
    timeout-minutes: 12
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PY_MAIN }}
          cache: 'pip'
          cache-dependency-path: |
            requirements*.txt
            pyproject.toml
            mypy.ini

      - name: Prime mypy cache
        uses: actions/cache@v4
        with:
          path: .mypy_cache
          key: ${{ runner.os }}-mypy-${{ env.PY_MAIN }}-${{ hashFiles('**/*.py','pyproject.toml','mypy.ini','.ruff.toml') }}
          restore-keys: |
            ${{ runner.os }}-mypy-${{ env.PY_MAIN }}-

      - name: Install type deps
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi
          python -m pip install "mypy>=1.8,<2" types-PyYAML types-requests
          python -m pip install -e .

      - name: mypy
        run: mypy src

  config-sanity:
    name: Config & schema sanity
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PY_MAIN }}
          cache: 'pip'
          cache-dependency-path: |
            requirements*.txt
            pyproject.toml

      - name: Install minimal deps
        run: |
          python -m pip install --upgrade pip
          python -m pip install "omegaconf==2.3.0" pyyaml jsonschema jq

      - name: Load all Hydra/YAML configs
        run: |
          python - << 'PY'
          import glob
          from omegaconf import OmegaConf
          files = sorted(glob.glob('configs/**/*.yaml', recursive=True))
          for f in files: OmegaConf.load(f)
          print(f"Loaded {len(files)} config files OK")
          PY

      - name: Validate submission schema presence
        run: test -f schemas/submission.schema.json && echo "Found schemas/submission.schema.json"

      - name: Validate submissions against schema (if any artifacts exist)
        run: |
          python - << 'PY'
          import json, glob, sys, pathlib
          from jsonschema import Draft202012Validator
          schema_path = pathlib.Path("schemas/submission.schema.json")
          if not schema_path.exists():
              print("No schema found; skipping.")
              sys.exit(0)
          schema = json.loads(schema_path.read_text())
          validator = Draft202012Validator(schema)
          bad = 0; checked = 0
          for f in glob.glob("artifacts/**/submission*.json", recursive=True):
              checked += 1
              data = json.loads(open(f).read())
              errs = sorted(validator.iter_errors(data), key=lambda e: e.path)
              if errs:
                  bad += 1
                  print(f"::error file={f}::Schema violations ({len(errs)})")
          print(f"Checked {checked} submission JSON file(s); failures={bad}")
          sys.exit(1 if bad else 0)
          PY

  tests:
    name: Unit tests (Py ${{ matrix.py }})
    runs-on: ubuntu-latest
    timeout-minutes: 28
    strategy:
      fail-fast: false
      matrix:
        py: ['3.10', '3.11', '3.12']
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.py }}
          cache: 'pip'
          cache-dependency-path: |
            requirements*.txt
            pyproject.toml
            setup.cfg
            setup.py

      - name: Install package + test deps
        run: |
          python -m pip install --upgrade pip wheel
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi
          python -m pip install -e .
          python -m pip install "pytest>=8,<9" "pytest-cov>=4,<5" "pytest-xdist>=3,<4"

      - name: PyTest (fast) + coverage
        env:
          PYTHONWARNINGS: "ignore::DeprecationWarning"
          SM_SUBMISSION_BINS: "283"
        run: |
          mkdir -p reports
          pytest -q -n auto --disable-warnings --maxfail=1 \
            --cov=src --cov-branch --cov-report=xml:reports/coverage.xml \
            --durations=25 \
            --junitxml=reports/tests-junit.xml

      - name: Upload reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-artifacts-${{ matrix.py }}
          path: |
            reports/
            ${{ env.COVERAGE_FILE }}
          if-no-files-found: ignore
          retention-days: ${{ env.ARTIFACT_RETENTION_DAYS }}

      - name: Publish Unit Test Results
        if: always()
        uses: EnricoMi/publish-unit-test-result-action@v2
        with:
          files: reports/tests-junit.xml

      - name: Publish Coverage Summary
        if: always()
        uses: irongut/CodeCoverageSummary@v1.3.0
        with:
          filename: reports/coverage.xml
          format: markdown
          output: both

  dvc-cli:
    name: DVC + CLI smoke
    runs-on: ubuntu-latest
    timeout-minutes: 25
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PY_MAIN }}
          cache: 'pip'
          cache-dependency-path: |
            requirements*.txt
            pyproject.toml
            poetry.lock

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi
          python -m pip install -e .
          python -m pip install "dvc[s3]>=3,<4"

      # Uncomment to enable AWS OIDC + S3 remote checks (set AWS_ROLE_ARN secret)
      # - name: AWS OIDC
      #   uses: aws-actions/configure-aws-credentials@v4
      #   with:
      #     role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
      #     aws-region: us-east-1

      - name: DVC dry-run
        env: { DVC_NO_ANALYTICS: "true" }
        run: |
          dvc version
          dvc doctor
          dvc repro --dry

      - name: CLI help smoke
        run: |
          python -m spectramind --help
          python -m spectramind calibrate --help
          python -m spectramind train --help
          python -m spectramind predict --help
          python -m spectramind diagnose --help
          python -m spectramind submit --help

  package:
    name: Build & verify package
    runs-on: ubuntu-latest
    timeout-minutes: 12
    needs: [lint, types, config-sanity, tests]
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PY_MAIN }}
          cache: 'pip'
          cache-dependency-path: |
            requirements*.txt
            pyproject.toml

      - name: Build sdist/wheel (deterministic)
        env:
          SOURCE_DATE_EPOCH: "1704067200"  # 2024-01-01 for reproducible wheels
        run: |
          python -m pip install --upgrade pip build twine
          python -m build
          twine check dist/*
          ls -lh dist/

      - name: Smoke import from built wheel
        run: |
          python -m venv .venv_pkg && . .venv_pkg/bin/activate
          pip install dist/*.whl
          python - <<'PY'
          import importlib, sys
          m = importlib.import_module("spectramind")
          print("Imported:", m.__name__, "Py", sys.version.split()[0])
          PY

      - name: Upload dist artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist
          path: dist/*
          retention-days: ${{ env.ARTIFACT_RETENTION_DAYS }}