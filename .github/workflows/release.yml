name: release

on:
  push:
    tags:
      - "v*"                          # e.g. v1.2.0 or v1.2.0-rc.1
  workflow_dispatch:

permissions:
  contents: read
  actions: read
  packages: read
  id-token: none
  security-events: none

concurrency:
  group: release-${{ github.ref }}
  cancel-in-progress: false

env:
  PYTHON_VERSION: "3.11"
  IMAGE_NAME: ghcr.io/${{ github.repository }}
  VERSION_FILE: VERSION
  KAGGLE_BUNDLE: artifacts/submission.zip
  ARTIFACT_RETENTION_DAYS: 30
  RELEASE_PLATFORMS: "linux/amd64"   # set to "linux/amd64,linux/arm64" for multi-arch

jobs:
  validate:
    name: Validate tag, VERSION, and pyproject
    runs-on: ubuntu-latest
    permissions: { contents: read }
    outputs:
      tag: ${{ steps.tag.outputs.tag }}
      ver: ${{ steps.version.outputs.version }}
      prerelease: ${{ steps.prerelease.outputs.prerelease }}
    steps:
      - name: Checkout (full history)
        uses: actions/checkout@3df4ab11eba7bda6032a0b82a6bb43b11571feac # v4
        with: { fetch-depth: 0 }

      - name: Extract tag
        id: tag
        run: echo "tag=${GITHUB_REF##*/}" >> "$GITHUB_OUTPUT"

      - name: Read VERSION
        id: version
        run: |
          test -f "${{ env.VERSION_FILE }}" || { echo "::error::Missing ${{ env.VERSION_FILE }}"; exit 1; }
          VER="$(tr -d ' \n' < "${{ env.VERSION_FILE }}")"
          test -n "$VER" || { echo "::error::VERSION is empty"; exit 1; }
          if ! echo "$VER" | grep -Eq '^[0-9]+\.[0-9]+\.[0-9]+([-.](rc\.[0-9]+|post[0-9]+|dev[0-9]+))?$'; then
            echo "::warning::VERSION may not conform to expected semver/pre-release pattern: $VER"
          fi
          echo "version=$VER" >> "$GITHUB_OUTPUT"
          echo "VERSION => $VER"

      - name: Validate tag == v$(cat VERSION)
        run: |
          TAG="${{ steps.tag.outputs.tag }}"
          VER="${{ steps.version.outputs.version }}"
          if [ "$TAG" != "v$VER" ]; then
            echo "::error title=Tag/Version mismatch::Tag $TAG != v$VER"; exit 1;
          fi
          echo "✅ Tag $TAG matches VERSION v$VER"

      - name: Cross-check pyproject.toml version
        run: |
          if [ -f pyproject.toml ]; then
            PVER=$(python - <<'PY'
from pathlib import Path
import re
t = Path("pyproject.toml").read_text()
m = re.search(r'(?m)^\s*version\s*=\s*"([^"]+)"\s*$', t)
print(m.group(1) if m else "")
PY
)
            if [ -n "$PVER" ] && [ "$PVER" != "${{ steps.version.outputs.version }}" ]; then
              echo "::error::pyproject version ($PVER) != VERSION (${{ steps.version.outputs.version }})"
              exit 1
            fi
            echo "✅ pyproject version matches"
          else
            echo "::notice::No pyproject.toml present — skipping version cross-check."
          fi

      - name: Determine pre-release (hyphen means prerelease)
        id: prerelease
        run: |
          TAG="${{ steps.tag.outputs.tag }}"
          [[ "$TAG" =~ ^v[0-9]+\.[0-9]+\.[0-9]+- ]] && P=true || P=false
          echo "prerelease=$P" >> "$GITHUB_OUTPUT"

  build:
    name: Build Python dist, package, and container
    needs: validate
    runs-on: ubuntu-latest
    permissions:
      contents: write          # upload artifacts
      packages: write          # push GHCR image
      id-token: write          # keyless signing/attestation
    outputs:
      ver: ${{ steps.v.outputs.ver }}
      image_digest: ${{ steps.buildx.outputs.digest }}
      built_image: ${{ steps.guard.outputs.built_image }}
    steps:
      - name: Checkout (full history)
        uses: actions/checkout@3df4ab11eba7bda6032a0b82a6bb43b11571feac # v4
        with: { fetch-depth: 0 }

      - name: Set up Python
        uses: actions/setup-python@0b93645e9fea7318efd9b4012f1f1a1f4f6c21fc # v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"
          cache-dependency-path: |
            **/pyproject.toml
            **/setup.cfg
            **/setup.py
            **/requirements*.txt

      - name: Install build deps
        run: |
          python -m pip install --upgrade pip
          pip install --upgrade build twine

      - name: Build wheel + sdist (reproducible)
        env:
          SOURCE_DATE_EPOCH: "1704067200"  # 2024-01-01 for deterministic archives
          PYTHONHASHSEED: "0"
        run: |
          python -m build
          twine check dist/*
          ls -lh dist/

      - name: Generate SHA256SUMS for dist/*
        working-directory: dist
        run: |
          : > SHA256SUMS.txt
          for f in *; do sha256sum "$f" >> SHA256SUMS.txt; done
          cat SHA256SUMS.txt

      - name: Install Cosign
        uses: sigstore/cosign-installer@1f9f5f017ca3f4f5a82bb2fc77a70b82e40601f1 # v3.7.0

      - name: Sign Python dist (keyless via OIDC)
        working-directory: dist
        env:
          COSIGN_EXPERIMENTAL: "true"
        run: |
          for f in *; do
            cosign sign-blob --yes "$f" \
              --output-signature "$f.sig" \
              --output-certificate "$f.cert"
          done

      - name: Make Kaggle submission bundle (if script exists)
        run: |
          if [ -x scripts/package_submission.sh ]; then
            mkdir -p artifacts
            bash scripts/package_submission.sh
            if [ -f "${{ env.KAGGLE_BUNDLE }}" ]; then
              ( cd artifacts && sha256sum "$(basename "${{ env.KAGGLE_BUNDLE }}")" > SUBMISSION.SHA256SUM )
            else
              echo "::warning::Kaggle bundle expected at ${{ env.KAGGLE_BUNDLE }} not found"
            fi
          else
            echo "No scripts/package_submission.sh; skipping."
          fi

      - name: Upload Python dist (+sigs)
        uses: actions/upload-artifact@834a144ee995460fba8ed112a2fc961b36a5ec5a # v4
        with:
          name: python-dist
          path: dist/*
          if-no-files-found: error
          retention-days: ${{ env.ARTIFACT_RETENTION_DAYS }}

      - name: Upload Kaggle bundle (if present)
        if: ${{ hashFiles(env.KAGGLE_BUNDLE) != '' }}
        uses: actions/upload-artifact@834a144ee995460fba8ed112a2fc961b36a5ec5a # v4
        with:
          name: kaggle-submission
          path: |
            ${{ env.KAGGLE_BUNDLE }}
            artifacts/SUBMISSION.SHA256SUM
          retention-days: 14

      - name: Upload diagnostics & metrics (if present)
        uses: actions/upload-artifact@834a144ee995460fba8ed112a2fc961b36a5ec5a # v4
        with:
          name: diagnostics-and-metrics
          path: |
            artifacts/**/*.html
            artifacts/**/*.json
            metrics/**/*.json
          if-no-files-found: ignore
          retention-days: ${{ env.ARTIFACT_RETENTION_DAYS }}

      # ---------- Guard & Container build/push ----------
      - name: Guard: is Dockerfile present?
        id: guard
        shell: bash
        run: |
          if [ -f Dockerfile ]; then
            echo "built_image=true" >> "$GITHUB_OUTPUT"
          else
            echo "::notice::No Dockerfile found — skipping container build/push."
            echo "built_image=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Docker login (GHCR)
        if: steps.guard.outputs.built_image == 'true'
        uses: docker/login-action@9780b0c442fbb1117ed29e0efdff1e18412f7567 # v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Docker metadata
        if: steps.guard.outputs.built_image == 'true'
        id: meta
        uses: docker/metadata-action@8e5442c4ef9f78752691e2a88c2ef49dc42b97de # v5
        with:
          images: ${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=tag
            type=raw,value=latest
          labels: |
            org.opencontainers.image.source=https://github.com/${{ github.repository }}
            org.opencontainers.image.title=SpectraMind V50
            org.opencontainers.image.description=NeurIPS 2025 Ariel Data Challenge — Spectral extraction & submission toolkit
            org.opencontainers.image.version=${{ needs.validate.outputs.tag }}
            org.opencontainers.image.revision=${{ github.sha }}
            org.opencontainers.image.licenses=Apache-2.0

      - name: Set up Buildx
        if: steps.guard.outputs.built_image == 'true'
        uses: docker/setup-buildx-action@2b51285047da1547ffb1b2203d8be4c0af6b1f20 # v3

      - name: (Optional) Enable QEMU for multi-arch
        if: steps.guard.outputs.built_image == 'true' && contains(env.RELEASE_PLATFORMS, 'arm64')
        uses: docker/setup-qemu-action@49b3bc8e6bdd4a60e6116a5414239cba5943d3cf # v3

      - name: Build & Push (with SBOM + provenance)
        if: steps.guard.outputs.built_image == 'true'
        id: buildx
        uses: docker/build-push-action@5cd11c3a4ced054e52742c5fd54dca954e0edd85 # v6
        with:
          context: .
          file: ./Dockerfile
          platforms: ${{ env.RELEASE_PLATFORMS }}
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          sbom: true
          provenance: mode=max
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Extract version
        id: v
        run: echo "ver=$(tr -d ' \n' < "${{ env.VERSION_FILE }}")" >> "$GITHUB_OUTPUT"

      - name: Sign images (keyless default)
        if: steps.guard.outputs.built_image == 'true'
        env:
          COSIGN_EXPERIMENTAL: "true"
        run: |
          cosign sign --yes "${{ env.IMAGE_NAME }}:${{ steps.v.outputs.ver }}"
          cosign sign --yes "${{ env.IMAGE_NAME }}:latest"

      - name: Attest build provenance (GitHub attestation)
        if: steps.guard.outputs.built_image == 'true'
        uses: actions/attest-build-provenance@bdd51370d99a66c718e0de0492932ad2c8c24a73 # v1
        with:
          subject-name: ${{ env.IMAGE_NAME }}
          subject-digest: ${{ steps.buildx.outputs.digest }}
          push-to-registry: true

  scan:
    name: Trivy FS & Image Scan
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write   # SARIF upload
      actions: read
      packages: read
    steps:
      - name: Checkout
        uses: actions/checkout@3df4ab11eba7bda6032a0b82a6bb43b11571feac # v4

      - name: Run Trivy (filesystem)
        uses: aquasecurity/trivy-action@f95f286e1f986924f5d54f71c606a05743ee69ac # 0.28.0
        with:
          scan-type: fs
          format: sarif
          output: trivy-fs.sarif
          ignore-unfixed: true
          severity: CRITICAL,HIGH

      - name: Run Trivy (image)
        if: needs.build.outputs.built_image == 'true'
        uses: aquasecurity/trivy-action@f95f286e1f986924f5d54f71c606a05743ee69ac # 0.28.0
        with:
          image-ref: ${{ env.IMAGE_NAME }}:${{ needs.build.outputs.ver }}
          format: sarif
          output: trivy-image.sarif
          ignore-unfixed: true
          vuln-type: os,library
          severity: CRITICAL,HIGH

      - name: Upload Trivy SARIF (FS)
        uses: github/codeql-action/upload-sarif@2e96272c09e5f38e4f0e2e2e7c0cf9c3fb9d0d82 # v3
        with:
          sarif_file: trivy-fs.sarif
        # category omitted to let GitHub dedupe cleanly

      - name: Upload Trivy SARIF (Image)
        if: needs.build.outputs.built_image == 'true'
        uses: github/codeql-action/upload-sarif@2e96272c09e5f38e4f0e2e2e7c0cf9c3fb9d0d82 # v3
        with:
          sarif_file: trivy-image.sarif

  sbom:
    name: Generate SBOMs
    needs: build
    runs-on: ubuntu-latest
    permissions: { contents: write }
    steps:
      - name: Checkout
        uses: actions/checkout@3df4ab11eba7bda6032a0b82a6bb43b11571feac # v4

      - name: Repo SBOM (CycloneDX JSON)
        uses: anchore/sbom-action@5c043a5065ad9009a4633986c724c8da7b34fd55 # v0
        with:
          path: .
          output-file: sbom-repo.cdx.json
          format: cyclonedx-json

      - name: Python deps SBOM (CycloneDX)
        uses: actions/setup-python@0b93645e9fea7318efd9b4012f1f1a1f4f6c21fc # v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"
      - run: |
          pip install --upgrade cyclonedx-bom
          cyclonedx-bom -o sbom-python.cdx.json || true

      - name: Image SBOM (Syft → CycloneDX)
        if: needs.build.outputs.built_image == 'true'
        run: |
          curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/local/bin v1.16.0
          syft "${{ env.IMAGE_NAME }}:${{ needs.build.outputs.ver }}" -o cyclonedx-json > sbom-image.cdx.json || true

      - name: Upload SBOMs
        uses: actions/upload-artifact@834a144ee995460fba8ed112a2fc961b36a5ec5a # v4
        with:
          name: sboms
          path: |
            sbom-repo.cdx.json
            sbom-python.cdx.json
            sbom-image.cdx.json
          if-no-files-found: ignore
          retention-days: ${{ env.ARTIFACT_RETENTION_DAYS }}

  release:
    name: Create GitHub Release
    needs: [validate, build, sbom, scan]
    runs-on: ubuntu-latest
    permissions: { contents: write }
    steps:
      - name: Checkout
        uses: actions/checkout@3df4ab11eba7bda6032a0b82a6bb43b11571feac # v4

      - name: Download all artifacts
        uses: actions/download-artifact@65d8626605736c8d5f6ac075fa365286f27502cf # v5
        with: { path: release-assets }

      - name: Flatten artifacts into assets/
        id: gather
        run: |
          mkdir -p assets
          shopt -s globstar nullglob
          for f in release-assets/**/*; do [ -f "$f" ] && cp -v "$f" assets/; done
          if [ "${{ needs.build.outputs.built_image }}" = "true" ]; then
            echo "${{ needs.build.outputs.image_digest }}" > assets/image-digest.txt
          fi
          echo "count=$(ls -1 assets | wc -l)" >> "$GITHUB_OUTPUT"
          ls -l assets || true

      - name: Create Release (auto notes)
        id: gh_release
        uses: softprops/action-gh-release@f9a232f431acab9f63a0d1b289c9bcbf0d105cbe # v2
        with:
          name: ${{ needs.validate.outputs.tag }}
          tag_name: ${{ needs.validate.outputs.tag }}
          draft: false
          prerelease: ${{ needs.validate.outputs.prerelease }}
          generate_release_notes: true
          files: assets/**
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Log Release URL
        run: echo "Release => ${{ steps.gh_release.outputs.url }}"

  docs:
    name: Build & Publish Docs (MkDocs)
    needs: validate
    runs-on: ubuntu-latest
    if: ${{ github.ref_type == 'tag' }}
    permissions:
      contents: read
      pages: write
      id-token: write
    steps:
      - name: Checkout
        uses: actions/checkout@3df4ab11eba7bda6032a0b82a6bb43b11571feac # v4
        with: { fetch-depth: 0 }

      - name: Set up Python
        uses: actions/setup-python@0b93645e9fea7318efd9b4012f1f1a1f4f6c21fc # v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Install mkdocs + plugins
        run: |
          pip install --upgrade mkdocs mkdocs-material mkdocs-git-revision-date-localized-plugin || true

      - name: Build docs
        run: mkdocs build --strict

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@d4b503b8b523dd6e3b9c8e2f1b6cf59a445e6b72 # v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: site
          publish_branch: gh-pages
          keep_files: false
          commit_message: "docs: publish ${{ needs.validate.outputs.tag }}"

  verify-dist:
    name: Verify dist checksums & signatures
    needs: build
    runs-on: ubuntu-latest
    if: ${{ secrets.PYPI_API_TOKEN != '' || secrets.TEST_PYPI_API_TOKEN != '' }}
    permissions:
      contents: read
      id-token: write
    steps:
      - name: Download python dist
        uses: actions/download-artifact@65d8626605736c8d5f6ac075fa365286f27502cf # v5
        with:
          name: python-dist
          path: dist

      - name: Verify checksums
        working-directory: dist
        run: sha256sum -c SHA256SUMS.txt

      - name: Verify signatures (OIDC, repo subject)
        working-directory: dist
        env:
          COSIGN_EXPERIMENTAL: "true"
        run: |
          for f in *; do
            [ -f "$f.sig" ] || continue
            cosign verify-blob \
              --certificate "$f.cert" \
              --signature "$f.sig" \
              --certificate-identity-regexp "https://github.com/${{ github.repository }}/*" \
              --certificate-oidc-issuer "https://token.actions.githubusercontent.com" \
              "$f"
          done

  testpypi-publish:
    name: Publish to TestPyPI (optional)
    needs: [validate, build, verify-dist]
    runs-on: ubuntu-latest
    if: ${{ secrets.TEST_PYPI_API_TOKEN != '' }}
    permissions: { contents: read }
    steps:
      - name: Download python dist
        uses: actions/download-artifact@65d8626605736c8d5f6ac075fa365286f27502cf # v5
        with:
          name: python-dist
          path: dist

      - name: Verify checksums
        working-directory: dist
        run: sha256sum -c SHA256SUMS.txt

      - name: Publish to TestPyPI
        uses: pypa/gh-action-pypi-publish@1f3c6a3b0c5d8d8a2ff1a2906c24a3b2f5cae1f4 # v1.13.0
        with:
          repository-url: https://test.pypi.org/legacy/
          user: __token__
          password: ${{ secrets.TEST_PYPI_API_TOKEN }}
          skip-existing: true

  pypi-publish:
    name: Publish to PyPI (optional)
    needs: [validate, build, verify-dist, testpypi-publish]
    runs-on: ubuntu-latest
    if: ${{ secrets.PYPI_API_TOKEN != '' }}
    permissions: { contents: read }
    steps:
      - name: Download python dist
        uses: actions/download-artifact@65d8626605736c8d5f6ac075fa365286f27502cf # v5
        with:
          name: python-dist
          path: dist

      - name: Verify checksums
        working-directory: dist
        run: sha256sum -c SHA256SUMS.txt

      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@1f3c6a3b0c5d8d8a2ff1a2906c24a3b2f5cae1f4 # v1.13.0
        with:
          user: __token__
          password: ${{ secrets.PYPI_API_TOKEN }}
          skip-existing: true
