# ==============================================================================
# Dockerfile.ci.cuda — SpectraMind V50 (CI GPU image, Kaggle-aligned)
# ------------------------------------------------------------------------------
# • CUDA 12.1 + cuDNN 8 on Ubuntu 22.04 (matches PyTorch cu121 wheels)
# • Python 3.11 by default (toggle PYVER=3.10 to mirror Kaggle notebooks)
# • Isolated venv at /opt/venv (no system-site contamination)
# • Deterministic Torch stack from cu121 index
# • Lean apt footprint, non-root user, proper signal handling via tini
# ==============================================================================

# IMPORTANT: use CUDA 12.1 runtime to match cu121 wheels (torch/cuDNN parity)
FROM nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04

# ---- Build args (flip PYVER to 3.10 for Kaggle parity) ------------------------
ARG PYVER=3.11

# Optional Torch versions (keep in sync with your pins)
ARG TORCH_VER=2.3.1
ARG TVISION_VER=0.18.1
ARG TAUDIO_VER=2.3.1

# ---- Base env ----------------------------------------------------------------
ENV DEBIAN_FRONTEND=noninteractive \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONFAULTHANDLER=1 \
    LC_ALL=C.UTF-8 \
    LANG=C.UTF-8 \
    VIRTUAL_ENV=/opt/venv \
    PATH=/opt/venv/bin:/usr/local/bin:/usr/bin:/bin \
    # Torch / NCCL stability knobs (safe defaults for CI)
    CUDA_DEVICE_ORDER=PCI_BUS_ID \
    NCCL_P2P_DISABLE=0 \
    NCCL_IB_DISABLE=1

SHELL ["/bin/bash", "-lc"]

# ---- System deps (pinned & minimal) ------------------------------------------
RUN set -euxo pipefail \
 && apt-get update \
 && apt-get install -y --no-install-recommends \
      ca-certificates curl git jq pciutils tini build-essential \
      software-properties-common \
 && rm -rf /var/lib/apt/lists/*

# ---- Python install (3.11 default via deadsnakes; 3.10 via system python) ----
RUN set -euxo pipefail; \
 if [[ "${PYVER}" == "3.10" ]]; then \
   apt-get update && apt-get install -y --no-install-recommends \
     python3 python3-venv python3-dev python3-pip && \
   rm -rf /var/lib/apt/lists/* && \
   PYBIN=python3; \
 else \
   add-apt-repository -y ppa:deadsnakes/ppa && apt-get update && \
   apt-get install -y --no-install-recommends \
     "python${PYVER}" "python${PYVER}-venv" "python${PYVER}-dev" python3-pip && \
   rm -rf /var/lib/apt/lists/* && \
   PYBIN="python${PYVER}"; \
 fi; \
 "${PYBIN}" -m venv "${VIRTUAL_ENV}" && \
 "${VIRTUAL_ENV}/bin/python" -m pip install --upgrade --no-cache-dir \
   pip==24.2 setuptools==72.2.0 wheel==0.44.0

# ---- Torch stack (CUDA 12.1 wheels) ------------------------------------------
# NOTE: The cu121 index serves the correct CUDA build; do NOT append +cu121.
RUN set -euxo pipefail \
 && python -m pip install --upgrade --no-cache-dir \
      --index-url https://download.pytorch.org/whl/cu121 \
      "torch==${TORCH_VER}" \
      "torchvision==${TVISION_VER}" \
      "torchaudio==${TAUDIO_VER}"

# ---- Optional runtime dependencies -------------------------------------------
# Keep non-fatal if the requirements file isn't present at build-time.
COPY requirements-kaggle.txt /tmp/requirements-kaggle.txt
RUN set -euxo pipefail; \
 if [[ -s /tmp/requirements-kaggle.txt ]]; then \
   python -m pip install --no-cache-dir -r /tmp/requirements-kaggle.txt; \
 else \
   echo "No requirements-kaggle.txt found; skipping."; \
 fi

# ---- Non-root user & workspace -----------------------------------------------
RUN useradd -ms /bin/bash runner
USER runner
WORKDIR /workspace

# ---- Labels for provenance ----------------------------------------------------
LABEL org.opencontainers.image.title="SpectraMind V50 CI CUDA Image" \
      org.opencontainers.image.description="CUDA 12.1 + cuDNN 8, Python ${PYVER}, Torch cu121" \
      org.opencontainers.image.source="https://github.com/your-org/spectramind-v50" \
      org.opencontainers.image.licenses="MIT"

# ---- Entry & health-friendly defaults ----------------------------------------
# tini ensures signals reach Python, preventing zombie processes in CI.
ENTRYPOINT ["/usr/bin/tini", "--"]

# Quick torch/cuDNN sanity print (GPU availability depends on runtime)
CMD python - <<'PY'
import sys, torch
print("Python:", sys.version.split()[0])
print("Torch:", torch.__version__, "CUDA build:", torch.version.cuda)
try:
    import torch.backends.cudnn as cudnn
    print("cuDNN:", cudnn.version())
except Exception:
    print("cuDNN: n/a")
print("CUDA visible devices:", torch.cuda.device_count())
print("CUDA available:", torch.cuda.is_available())
PY
