# ==============================================================================
# dvc.yaml — SpectraMind V50 (reproducible pipeline, hardened)
# ------------------------------------------------------------------------------
# Stages: calibrate → preprocess → train → predict → diagnose → submit
#
# Notes:
#   • We keep outputs deterministic (no timestamps) to make DVC caching effective.
#   • Hydra's run dir is overridden explicitly to fixed locations per stage.
#   • Use DVC Experiments to switch Hydra groups/params, e.g.:
#       dvc exp run \
#         -S hydra.env=kaggle \
#         -S hydra.model=v50 \
#         -S hydra.training=fast_ci
#   • Persist calibrated/processed data for reuse & Kaggle packaging.
#   • Keep heavy logs out of cache; track small JSON metrics.
# ==============================================================================

stages:
  calibrate:
    desc: "Raw → CALIBRATED tensors (FGS1 + AIRS); physics-based calibration only"
    cmd: >
      python -m spectramind calibrate
      --in data/raw
      --out data/calibrated
      hydra.run.dir=artifacts/_hydra/calibrate
    deps:
      - data/raw
      - configs
      - src
      - params.yaml
    params:
      - hydra.env
      - hydra.data
      - hydra.calib
    outs:
      - path: data/calibrated
        persist: true

  preprocess:
    desc: "CALIBRATED → PROCESSED; mask/detrend/normalize/bin/window/pack/tokenize/export"
    cmd: >
      python -m spectramind preprocess
      --in data/calibrated
      --out data/processed
      hydra.run.dir=artifacts/_hydra/preprocess
    deps:
      - data/calibrated
      - configs
      - src
      - params.yaml
    params:
      - hydra.env
      - hydra.data
      - hydra.preprocess
    outs:
      - path: data/processed
        persist: true

  train:
    desc: "Train dual-channel encoders + heteroscedastic decoder (μ,σ)"
    cmd: >
      python -m spectramind train
      paths.run_dir=artifacts/train
      hydra.run.dir=artifacts/train/_hydra
    deps:
      - data/processed
      - configs
      - src
      - params.yaml
    params:
      - hydra.env
      - hydra.data
      - hydra.model
      - hydra.training
      - hydra.loss
      - hydra.logger
    outs:
      # keep binary ckpt in a deterministic place for downstream stages
      - path: artifacts/train/ckpt.pt
        checkpoint: true
      # keep textual metrics small and cacheable
      - path: artifacts/train/metrics.json
        cache: true
    outs_no_cache:
      - logs/train
    metrics:
      - artifacts/train/metrics.json:
          type: json
          xpath: .
          cache: false

  predict:
    desc: "Inference on processed data → predictions CSV"
    cmd: >
      python -m spectramind predict
      --ckpt artifacts/train/ckpt.pt
      --out-csv artifacts/predictions/preds.csv
      hydra.run.dir=artifacts/predictions/_hydra
    deps:
      - artifacts/train/ckpt.pt
      - data/processed
      - configs
      - src
      - params.yaml
    params:
      - hydra.env
      - hydra.data
    outs:
      - path: artifacts/predictions/preds.csv
        cache: true

  diagnose:
    desc: "Diagnostics: GLL/MAE/RMSE/coverage + plots + report"
    cmd: >
      python -m spectramind diagnose
      --pred-csv artifacts/predictions/preds.csv
      --out-dir artifacts/diagnostics
      hydra.run.dir=artifacts/diagnostics/_hydra
    deps:
      - artifacts/predictions/preds.csv
      - configs
      - src
      - params.yaml
    params:
      - hydra.env
      - hydra.data
    outs:
      - path: artifacts/diagnostics/report.html
        cache: true
      - path: artifacts/diagnostics/plots
        cache: true
    plots:
      - artifacts/diagnostics/plots:
          cache: false
    metrics:
      - artifacts/diagnostics/summary.json:
          type: json
          xpath: .
          cache: false
    # Optional: live logging (enable in CLI if desired)
    # live:
    #   artifacts/diagnostics/live:
    #     summary: true
    #     html: true

  submit:
    desc: "Package submission artifacts (ZIP with MANIFEST); schema-validate"
    cmd: >
      bin/sm_submit.sh --skip-predict
    deps:
      - artifacts/predictions/preds.csv
      - schemas/submission.tableschema.sample_id.json
      - schemas/submission_header.csv
      - bin/sm_submit.sh
      - src
      - configs
    outs:
      - path: outputs/submission/submission.zip
        cache: true
      - path: outputs/submission/submission.csv
        cache: true
    # If the bundle embeds timestamps and you want forced rebuilds:
    # always_changed: true

  package-precalibrated:
    desc: "Zip CALIBRATED tensors for Kaggle dataset attachment (runtime saver)"
    cmd: >
      bash scripts/package_precalibrated.sh data/calibrated artifacts/kaggle/precalibrated.zip
    deps:
      - data/calibrated
      - scripts/package_precalibrated.sh
    outs:
      - path: artifacts/kaggle/precalibrated.zip
        cache: true
